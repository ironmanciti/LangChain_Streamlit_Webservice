{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "_HHWhmwf3kJB",
   "metadata": {
    "id": "_HHWhmwf3kJB"
   },
   "source": [
    "# **추출 체인(Extraction Chain) 구축하기**\n",
    "\n",
    "이 노트북에서는 **채팅 모델(Chat Models)**의 **도구 호출(Tool Calling)** 기능을 사용하여 **비정형 텍스트에서 구조화된 정보를 추출**하는 방법을 다룹니다. 또한 이 맥락에서 **Few-Shot 프롬프팅(Few-Shot Prompting)**을 사용하여 성능을 개선하는 방법을 시연할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6b970-2ea3-4192-951e-21237212b359",
   "metadata": {
    "id": "54d6b970-2ea3-4192-951e-21237212b359"
   },
   "source": [
    "## **스키마 (The Schema)**  \n",
    "\n",
    "먼저, 텍스트에서 어떤 정보를 추출할 것인지 **정의**해야 합니다.  \n",
    "\n",
    "이를 위해 **Pydantic**을 사용하여 **개인 정보(personal information)**를 추출하기 위한 예제 **스키마(schema)**를 정의할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11fa522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU \\\n",
    "# python-dotenv \\\n",
    "# langchain \\\n",
    "# langchain-community \\\n",
    "# openai \\\n",
    "# anthropic \\\n",
    "# langchain-openai \\\n",
    "# langchain-anthropic \\\n",
    "# langchain-google-genai \\\n",
    "# python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f98bacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d0aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional  \n",
    "from pydantic import BaseModel, Field \n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"\n",
    "    사람에 대한 정보.   \n",
    "    \"\"\"\n",
    "    # 이 Doc-string은 LLM에 'Person' 스키마에 대한 설명으로 전달됩니다.\n",
    "    # 사람의 이름\n",
    "    name: Optional[str] = Field(default=None, description=\"사람의 이름\")\n",
    "    # 사람의 머리 색상\n",
    "    hair_color: Optional[str] = Field(default=None, description=\"사람의 머리 색상\")\n",
    "    # 사람의 키 (미터 단위)\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, \n",
    "        description=\"미터 단위로 측정된 키\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f248dd54-e36d-435a-b154-394ab4ed6792",
   "metadata": {
    "id": "f248dd54-e36d-435a-b154-394ab4ed6792"
   },
   "source": [
    "## **스키마 정의의 두 가지 사례**\n",
    "\n",
    "1. **속성(attributes)**과 **스키마(schema)** 를 Pydantic으로 문서화:  \n",
    "   - 이 정보는 LLM에 전달되며, Pydantic 스키마를 통해 명확하게 정의되어 정보 추출의 품질을 개선하는 데 사용됩니다.\n",
    "     \n",
    "<pr></pr>\n",
    "\n",
    "2. **LLM이 정보를 지어내지 않도록 하세요!**  \n",
    "   - 위에서 각 속성에 `Optional`을 사용하여 LLM이 답을 모를 경우 `None`을 반환할 수 있도록 했습니다.\n",
    "  \n",
    "최상의 성능을 얻으려면 **스키마를 잘 문서화**하고, 텍스트에 추출할 정보가 없을 경우 모델이 결과를 **강제로 반환하지 않도록** 설정합니다.  \n",
    "\n",
    "\n",
    "## **추출기 (The Extractor)**\n",
    "\n",
    "이제 위에서 정의한 **스키마(schema)**를 사용하여 **정보 추출기(Information Extractor)**를 만들어 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4156fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional   \n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from pydantic import BaseModel, Field  \n",
    "\n",
    "# 사용자 정의 프롬프트 템플릿 정의\n",
    "# 텍스트에서 정보를 추출하기 위한 명확한 지침과 추가 컨텍스트를 제공합니다.\n",
    "\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 전문 정보 추출 알고리즘입니다. \"\n",
    "            \"텍스트에서 관련 정보만 추출하세요. \"\n",
    "            \"추출해야 할 속성의 값을 알지 못할 경우, \"\n",
    "            \"해당 속성의 값으로 null을 반환하세요.\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),   # 사용자 입력 텍스트를 프롬프트에 전달\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bf6a1-8e0c-4b6a-aa37-12fe9c42a6d9",
   "metadata": {
    "id": "832bf6a1-8e0c-4b6a-aa37-12fe9c42a6d9"
   },
   "source": [
    "**기능/도구 호출(Function/Tool Calling)**을 지원하는 모델을 사용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e409c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e0ab0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000152841606D0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001528416E880>, root_client=<openai.OpenAI object at 0x0000015284031400>, root_async_client=<openai.AsyncOpenAI object at 0x0000015284160730>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'Person', 'description': '사람에 대한 정보.   ', 'parameters': {'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': '사람의 이름'}, 'hair_color': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': '사람의 머리 색상'}, 'height_in_meters': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': '미터 단위로 측정된 키'}}, 'type': 'object'}}}], 'parallel_tool_calls': False, 'tool_choice': {'type': 'function', 'function': {'name': 'Person'}}}, config={}, config_factories=[])\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.Person'>])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM에서 구조화된 출력을 생성하도록 스키마 바인딩\n",
    "structured_llm = llm.with_structured_output(schema=Person)\n",
    "structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908bca50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='도날트 트럼프', hair_color='금발', height_in_meters='1.86')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"도날트 트럼프 대통령의 키는 186센티이고 금발입니다. 그의 친한 친구 John Doe는 은발입니다. 그 사람의 고향은 어디인가요?\"\n",
    "\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c493d-f9dc-4236-8da9-50f6919f5710",
   "metadata": {
    "id": "bd1c493d-f9dc-4236-8da9-50f6919f5710"
   },
   "source": [
    "LLM은 생성 모델이므로, 센티미터로 제공된 신장의 정보를 미터로 정확하게 추출하는 등의 놀라운 작업을 수행할 수 있습니다! 또한 스키마에 정의된 이름, 머리색, 키 외의 다른 내용은 무시하고 답변을 생성합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5ef0c-b8d1-4e12-bd0e-e2528de87fcc",
   "metadata": {
    "id": "28c5ef0c-b8d1-4e12-bd0e-e2528de87fcc"
   },
   "source": [
    "## 다중 엔터티\n",
    "\n",
    "많은 경우, 단일 엔티티가 아닌 여러 엔티티를 추출해야 합니다. 이는 Pydantic에서 모델을 서로 중첩하여 쉽게 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d348a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"\n",
    "    여러 사람들에 대한 추출된 데이터.\n",
    "    \"\"\"\n",
    "    peoples: List[Person]   # 여러 사람의 정보를 추출하기 위해 'Person' 모델의 리스트를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e18882b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(peoples=[Person(name='제프', hair_color='검은색', height_in_meters='1.83'), Person(name='안나', hair_color='검은색', height_in_meters=None)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(schema=Data)\n",
    "\n",
    "text = \"제 이름은 제프이고, 제 머리는 검은색이고 키는 6피트입니다. 안나는 저와 같은 색의 머리를 가지고 있습니다.\"\n",
    "\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1d770-bf4d-4de4-9e4f-7384872ef0dc",
   "metadata": {
    "id": "fba1d770-bf4d-4de4-9e4f-7384872ef0dc"
   },
   "source": [
    "**여러 엔티티**를 추출할 수 있도록 스키마가 설계되면, 텍스트에 관련 정보가 없을 경우 **빈 리스트(empty list)**를 반환하여 **아무런 엔티티도 추출하지 않을 수 있습니다.**  \n",
    "\n",
    "이는 일반적으로 **좋은 설계**입니다! 이를 통해 모델이 해당 엔티티를 반드시 감지하도록 강제하지 않을 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c590f366-050a-43d4-8c78-acf84ccfbf9b",
   "metadata": {
    "id": "c590f366-050a-43d4-8c78-acf84ccfbf9b"
   },
   "source": [
    "## **Few-Shot Prompting**  \n",
    "\n",
    "LLM 애플리케이션의 동작은 **Few-Shot 프롬프팅**을 사용하여 조정할 수 있습니다.  \n",
    "\n",
    "**챗 모델(Chat Models)**의 경우, 원하는 동작을 보여주는 **입력(input)**과 **응답(response)** 메시지 쌍의 시퀀스로 구성될 수 있습니다.  \n",
    "\n",
    "예를 들어, `user`와 `assistant` **메시지**가 번갈아 가며 나타나는 구조를 통해 `🦜` 기호의 의미를 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17e0276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"2 🦜 2\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"4\"},\n",
    "    {\"role\": \"user\", \"content\": \"2 🦜 3\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"5\"},\n",
    "    {\"role\": \"user\", \"content\": \"3 🦜 4\"},\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5691d07-e2b8-4ab3-a943-9b0b503e2549",
   "metadata": {
    "id": "b5691d07-e2b8-4ab3-a943-9b0b503e2549"
   },
   "source": [
    "**구조화된 출력(Structured Output)**은 종종 도구 호출(Tool Calling)을 기반으로 작동합니다. 이는 일반적으로 **도구 호출을 포함하는 AI 메시지(AI messages)**와 **도구 호출의 결과를 포함하는 도구 메시지(Tool messages)**의 생성을 포함합니다.  \n",
    "LangChain의 `tool_example_to_messages` 함수는 각 업체의 LLM에 맞추어 도구 호출 형식을 자동으로 포맷합니다. \n",
    "\n",
    "---\n",
    "\n",
    "### **LangChain의 유틸리티 함수: `tool_example_to_messages`**  \n",
    "각 모델 제공업체(OpenAI, Anthropic 등)마다 도구 호출 형식이 조금씩 다릅니다. LangChain의 tool_example_to_messages 함수는 Pydantic 객체만 있으면, 이를 모델 제공업체의 요구사항에 맞는 형식으로 자동 변환해주는 도구입니다. tool_example_to_messages는 개발자가 복잡한 포맷을 신경 쓰지 않고, Pydantic 객체만 제공하면 자동으로 올바른 메시지 형식을 만들어줍니다.\n",
    "\n",
    "---\n",
    "\n",
    "###  **동작 순서**  \n",
    "\n",
    "1. 입력 문자열: 사용자의 요청이나 질문을 문자열로 제공합니다.  \n",
    "2. Pydantic 객체: 사용할 도구나 함수의 입력 형식을 Pydantic 모델로 정의합니다.  \n",
    "3. 자동 포맷: LangChain이 이 두 가지를 조합해 모델 제공업체(OpenAI, Anthropic 등)에 맞는 메시지 포맷으로 자동 변환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c336bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 호출 예제를 메시지로 변환하기 위한 유틸리티 함수\n",
    "from langchain_core.utils.function_calling import tool_example_to_messages\n",
    "\n",
    "# Few-Shot Prompting 예제 데이터 정의\n",
    "# 입력 텍스트와 모델이 추출해야 할 데이터의 목표 형식(Target Schema) 쌍으로 정의\n",
    "examples = [\n",
    "    (\n",
    "        \"바다는 넓고 푸르다. 깊이가 20,000피트가 넘습니다.\",\n",
    "        Data(peoples=[]),   # 모델이 추출할 데이터 - 사람 정보가 없는 경우\n",
    "    ),\n",
    "    (\n",
    "        \"차박차박 유튜버는 프랑스에서 스페인까지 먼 여행을 했습니다.\",\n",
    "        Data(peoples=[Person(name=\"차박차박\", height_in_meters=None, hair_color=None)]),  # 모델이 추출할 데이터 - 차박차박에 대한 정보 추출\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 메시지 목록 초기화\n",
    "messages = []\n",
    "\n",
    "# 예제 데이터를 메시지로 변환\n",
    "for txt, expected_output in examples:\n",
    "    if expected_output.peoples:  # 사람 정보가 있는 경우\n",
    "        response = \"Detected people.\"\n",
    "    else:\n",
    "        response = \"Detected no people.\"\n",
    "\n",
    "    # tool_example_to_messages 함수를 사용해 입력 텍스트와 도구 호출 데이터를 메시지로 변환\n",
    "    messages.extend(tool_example_to_messages(txt, [expected_output], ai_response=response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beecc7a6-e423-4ca1-82b7-c2a751362fd6",
   "metadata": {
    "id": "beecc7a6-e423-4ca1-82b7-c2a751362fd6"
   },
   "source": [
    "결과를 살펴보면 다음 두 쌍의 예시가 8개의 메시지를 생성한 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "063091fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='바다는 넓고 푸르다. 깊이가 20,000피트가 넘습니다.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'a5e1d83c-16ad-4983-9009-a3cf5937ccca', 'type': 'function', 'function': {'name': 'Data', 'arguments': '{\"peoples\":[]}'}}]}, response_metadata={}, tool_calls=[{'name': 'Data', 'args': {'peoples': []}, 'id': 'a5e1d83c-16ad-4983-9009-a3cf5937ccca', 'type': 'tool_call'}]),\n",
       " ToolMessage(content='You have correctly called this tool.', tool_call_id='a5e1d83c-16ad-4983-9009-a3cf5937ccca'),\n",
       " AIMessage(content='Detected no people.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='차박차박 유튜버는 프랑스에서 스페인까지 먼 여행을 했습니다.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '89b74e2f-0677-4a5d-9ba7-90f9ba9e1e7b', 'type': 'function', 'function': {'name': 'Data', 'arguments': '{\"peoples\":[{\"name\":\"차박차박\",\"hair_color\":null,\"height_in_meters\":null}]}'}}]}, response_metadata={}, tool_calls=[{'name': 'Data', 'args': {'peoples': [{'name': '차박차박', 'hair_color': None, 'height_in_meters': None}]}, 'id': '89b74e2f-0677-4a5d-9ba7-90f9ba9e1e7b', 'type': 'tool_call'}]),\n",
       " ToolMessage(content='You have correctly called this tool.', tool_call_id='89b74e2f-0677-4a5d-9ba7-90f9ba9e1e7b'),\n",
       " AIMessage(content='Detected people.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91d5856c-917d-4d17-be86-da08a4c3b229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "바다는 넓고 푸르다. 깊이가 20,000피트가 넘습니다.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (a5e1d83c-16ad-4983-9009-a3cf5937ccca)\n",
      " Call ID: a5e1d83c-16ad-4983-9009-a3cf5937ccca\n",
      "  Args:\n",
      "    peoples: []\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Detected no people.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "차박차박 유튜버는 프랑스에서 스페인까지 먼 여행을 했습니다.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (89b74e2f-0677-4a5d-9ba7-90f9ba9e1e7b)\n",
      " Call ID: 89b74e2f-0677-4a5d-9ba7-90f9ba9e1e7b\n",
      "  Args:\n",
      "    peoples: [{'name': '차박차박', 'hair_color': None, 'height_in_meters': None}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Detected people.\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8846f0-8bd1-48e1-bc4d-a62fbfa6a9f4",
   "metadata": {
    "id": "dc8846f0-8bd1-48e1-bc4d-a62fbfa6a9f4"
   },
   "source": [
    "----\n",
    "이 메시지들을 Few-Shot Example로 Prompt에 포함할와 포함하지 않을 때의 성능을 비교해봅니다.   \n",
    "다음은, 사람이 포함되지 않은 메시지에 대한 llm의 response 비교 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25e9bc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(peoples=[Person(name='태양계', hair_color='없음', height_in_meters='0'), Person(name='지구', hair_color='푸른색', height_in_meters='0'), Person(name='달', hair_color='회색', height_in_meters='0')])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_no_people = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"태양계는 크지만, 지구에는 달이 단 하나뿐입니다.\",\n",
    "}\n",
    "\n",
    "structured_response = llm.with_structured_output(schema=Data)\n",
    "answer = structured_response.invoke([message_no_people])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b61a0adc-5b3a-422a-9b99-1e11d6d2de25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Person(name='태양계', hair_color='없음', height_in_meters='0'), Person(name='지구', hair_color='푸른색', height_in_meters='0'), Person(name='달', hair_color='회색', height_in_meters='0')]\n"
     ]
    }
   ],
   "source": [
    "print(answer.peoples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350e1298-14f1-48e4-b11c-534af643e3a6",
   "metadata": {
    "id": "350e1298-14f1-48e4-b11c-534af643e3a6"
   },
   "source": [
    "이 예제에서 모델은 사람에 대한 잘못된 응답을 생성할 가능성이 있습니다.  \n",
    "\n",
    "그러나 \"Detected no people\" 사례가 포함되어 있는 **Few-Shot Example**을 제공할 경우, 모델이 올바르게 작동하도록 유도할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52489feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(peoples=[])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = structured_response.invoke(messages + [message_no_people])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3538e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
