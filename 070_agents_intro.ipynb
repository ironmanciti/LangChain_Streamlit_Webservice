{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df78a71",
   "metadata": {
    "id": "1df78a71"
   },
   "source": [
    "# **에이전트(Agent) 구축하기**\n",
    "\n",
    "언어 모델(LLM) 자체는 **행동을 수행할 수 없습니다**  그저 텍스트를 출력할 뿐입니다.  \n",
    "LangChain의 주요 사용 사례 중 하나는 **에이전트(Agents)**를 만드는 것입니다.  \n",
    "\n",
    "**에이전트(Agents)**는 **LLM**을 **추론 엔진**으로 사용하여 어떤 행동을 취해야 하는지, 그리고 행동을 수행하는 데 필요한 입력이 무엇인지 결정하는 시스템입니다.  \n",
    "행동을 실행한 후 결과를 LLM에 다시 전달하여 **더 많은 행동이 필요한지** 또는 **작업을 종료해도 되는지**를 판단할 수 있습니다. 이는 종종 **도구 호출(tool-calling)**을 통해 이루어집니다.  \n",
    "\n",
    "---\n",
    "\n",
    "이 노트북에서는 **검색 엔진과 상호작용할 수 있는 에이전트**를 구축합니다.  \n",
    "- 사용자는 이 에이전트에게 질문을 할 수 있습니다.  \n",
    "- 에이전트가 검색 도구를 호출하는 과정을 볼 수 있습니다.  \n",
    "- 에이전트와 여러 차례 대화를 나눌 수 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "## **엔드 투 엔드 에이전트 (End-to-end Agent)**\n",
    "\n",
    "아래 코드는 **도구(tool)**를 사용하여 어떤 행동을 취해야 할지 결정하는 LLM을 활용한 **완전히 기능하는 에이전트**를 보여줍니다.  \n",
    "- 이 에이전트는 **일반적인 검색 도구**를 사용할 수 있습니다.  \n",
    "- **대화 메모리(conversational memory)**를 갖추고 있어 다중 턴 대화가 가능합니다.\n",
    "- 도구 정의 - 우리의 주요 선택 도구는 **Tavily**입니다. Tavily는 **검색 엔진**으로, LangChain에는 Tavily 검색 엔진을 쉽게 사용할 수 있도록 지원하는 **내장 도구**가 포함되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad23202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU \\\n",
    "# python-dotenv \\\n",
    "# langchain \\\n",
    "# langchain-community \\\n",
    "# openai \\\n",
    "# anthropic \\\n",
    "# langchain-openai \\\n",
    "# langchain-anthropic \\\n",
    "# langchain-google-genai \\\n",
    "# python-dotenv \\\n",
    "# langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157e49af-c63c-4bd6-b12a-97d9fbcd05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU tavily-python langgraph-checkpoint-sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00462d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6708222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain 추적(Tracing) 설정 활성화\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66db67fb-a9cb-4832-b691-11987faf4d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4fb8c-62fc-40a9-8361-7567b9d65765",
   "metadata": {},
   "source": [
    "##  **언어 모델과 도구 정의**\n",
    "\n",
    "먼저 언어 모델과 사용하려는 도구를 생성해야 합니다. 우리의 주요 선택 도구는 **Tavily**입니다. Tavily는 **검색 엔진**으로, LangChain에는 Tavily 검색 엔진을 쉽게 사용할 수 있도록 지원하는 **내장 도구**가 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a30d6999-dfda-4e2b-bf66-9ac47d082d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TavilySearchResults(max_results=2, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 검색 도구 설정 (최대 검색 결과 2개)\n",
    "search = TavilySearchResults(max_results=2)\n",
    "\n",
    "# 사용할 모든 도구를 하나의 리스트에 넣어서 나중에 참조할 수 있도록 설정\n",
    "tools = [search]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf4313f-92b1-45f0-9e2c-7ad6b6e2cc92",
   "metadata": {},
   "source": [
    "### 1) 도구 없이 LLM 만 호출할 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49cde2cb-8c10-4032-82ba-d5273f308225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 서울의 현재 날씨를 실시간으로 제공할 수는 없지만, 일반적으로 서울의 날씨는 계절에 따라 크게 다릅니다. 봄과 가을에는 온화한 날씨가 많고, 여름에는 덥고 습한 날이 많으며, 겨울에는 춥고 눈이 오는 날도 많습니다. 정확한 날씨 정보를 원하시면 기상청 웹사이트나 날씨 앱을 확인해 보시는 것을 추천합니다. 도움이 필요하시면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "print(model.invoke(\"안녕, 나는 서울에 살고 있어. 내가 사는 곳의 날씨를 알려줘\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3984cdc-1082-4b10-8a1f-4406d5bb32db",
   "metadata": {},
   "source": [
    "### 2) Agent 구축 않고 LLM에 도구 목록만 전달할 경우\n",
    "이제 이 모델이 도구 호출을 수행하도록 활성화하기 위해 `.bind_tools`를 사용하여 언어 모델에 이러한 도구에 대한 지식을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9652470-564f-481b-bc1e-3693167f31e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_Ky8RWC3mEGTWMEIbHUAJLWMJ', 'function': {'arguments': '{\"query\":\"서울 날씨\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 99, 'total_tokens': 120, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-b1661db9-fbf3-4b1a-9dda-d64b81ce4745-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '서울 날씨'}, 'id': 'call_Ky8RWC3mEGTWMEIbHUAJLWMJ', 'type': 'tool_call'}] usage_metadata={'input_tokens': 99, 'output_tokens': 21, 'total_tokens': 120, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# `bind_tools` 메서드를 사용하여 언어 모델이 특정 도구 목록을 사용할 수 있도록 설정합니다.\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "response = model_with_tools.invoke([HumanMessage(content=\"안녕, 나는 서울에 살고 있어. 내가 사는 곳의 날씨를 알려줘\")])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f004cc-922d-41c1-9a5c-31fd49efae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'tavily_search_results_json', 'args': {'query': '서울 날씨'}, 'id': 'call_Ky8RWC3mEGTWMEIbHUAJLWMJ', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1538289f-f695-40df-960e-b047891e5d99",
   "metadata": {},
   "source": [
    "모델은 우리가 **Tavily Search** 도구를 호출하라고 알려주며 도구 호출에 필요한 argument를 만들어 줍니다.  \n",
    "하지만 이것은 아직 해당 도구를 호출한 것이 아니라, 단지 호출해야 한다고 알려주는 것입니다. 실제로 도구를 호출하려면 **에이전트(agent)**를 만들어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a4d1db-59f1-4d71-a3c8-29851d4af9d7",
   "metadata": {},
   "source": [
    "## Agent 생성\n",
    "\n",
    "- LLM은 **상태를 저장하지 않는(stateless)** 이므로 이전 상호작용을 기억하지 않습니다. 에이전트에 메모리를 추가하려면 **체크포인터(checkpointer)**를 전달해야 합니다. 또한 에이전트를 호출할 때 `thread_id`를 함께 전달해야 합니다. 이를 통해 에이전트는 어느 스레드(대화)에서부터 상호작용을 이어가야 하는지 알 수 있습니다.\n",
    "\n",
    "- ReAct 에이전트를 구성하기 위해 Langgraph에서 제공하는 고수준 인터페이스(high-level interface)인 `create_react_agent`를 사용합니다. 이를 통해 에이전트 로직을 원하는 대로 세부적으로 수정할 수 있습니다. `create_react_agent`는 내부적으로 `.bind_tools`를 호출해 도구를 모델에 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5cb23e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트의 메모리 저장 객체 생성\n",
    "memory = MemorySaver()  \n",
    "\n",
    "# 에이전트 실행 객체 생성\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "# 에이전트 실행 구성 설정\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea2753-5f98-4b95-9568-0922b133f336",
   "metadata": {},
   "source": [
    "## 스트리밍 메시지  \n",
    "\n",
    "우리는 `.invoke`를 사용해 에이전트를 호출하고 최종 응답을 받는 방법을 알고 있습니다. 하지만 에이전트가 여러 단계를 실행해야 할 경우 시간이 오래 걸릴 수 있습니다.  \n",
    "중간 진행 상황을 보여주기 위해, 발생하는 메시지를 스트리밍 형태로 실시간 전송할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20a5ac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='안녕, 길동! 서울에 살고 있다니 멋지네. 서울에서 어떤 것들을 좋아해?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 94, 'total_tokens': 121, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='run-7541a69e-5ce4-461b-b317-5604230436aa-0', usage_metadata={'input_tokens': 94, 'output_tokens': 27, 'total_tokens': 121, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 에이전트 실행\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"안녕! 나는 길동이야. 서울에 살고 있어.\")]},\n",
    "    config\n",
    "):\n",
    "    print(chunk)  # 에이전트의 응답 출력\n",
    "    print(\"---------------------------------------------------------------------\")  # 응답 구분선 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b25c3df-6272-431e-9bbe-33d25ea1b516",
   "metadata": {},
   "source": [
    "#### 메모리가 필요한 질문 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01a41943-c87d-4927-ac0f-ead1b73b5bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='너의 이름은 길동이고, 서울에 살고 있다고 했어. 맞아?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 140, 'total_tokens': 161, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='run-eba1dca8-290d-46d4-b48a-998fb466bd67-0', usage_metadata={'input_tokens': 140, 'output_tokens': 21, 'total_tokens': 161, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"내 이름이 뭐고 어디에 살고 있다고 했지?\")]},\n",
    "    config\n",
    "):\n",
    "    print(chunk)  # 에이전트의 응답 출력\n",
    "    print(\"------------------------------------------------------------------------\")  # 응답 구분선 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47848675-bab3-49be-bb55-3c7213f5fc16",
   "metadata": {},
   "source": [
    "#### ReAct 패턴의 질문/응답 \n",
    "질문이 단순 정보 조회가 아닌, 추론과 행동을 반복해야 해결 가능한 질문\n",
    "예) 내가 사는 곳의 날씨를 알려줘 \n",
    "- Reasoning(추론) - 사용자의 위치를 알아야 하고, 날씨 API에서 날씨 정보를 가져와야 한다. (LLM 역할)  \n",
    "- Acting(행동) - TavilySearchResults API 호출 (LangChin 역할)  \n",
    "- Observation(관찰) - API로부터 \"오늘 서울은 맑음\"이라는 정보를 받았다. 이 것을 LLM에 다시 전달. (LangChain 역할)\n",
    "- Reasoning(추론) - \"이제 사용자에게 서울의 날씨가 맑다고 답변해야 한다.\"  (LLM의 역할)  \n",
    "- Answer(응답) - \"서울의 날씨는 맑음입니다.\" (LLM의 역할)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88bc07fc-b9b2-4c65-8b5b-12394f9218f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ddBYt55HfLgXwfnMH3PPbm4s', 'function': {'arguments': '{\"query\":\"서울 날씨\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 179, 'total_tokens': 200, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-adf4279e-866c-4c60-a14d-f29b293b3f04-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '서울 날씨'}, 'id': 'call_ddBYt55HfLgXwfnMH3PPbm4s', 'type': 'tool_call'}], usage_metadata={'input_tokens': 179, 'output_tokens': 21, 'total_tokens': 200, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "-----------------------------------------------------------------------\n",
      "{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://weather.com/ko-KR/weather/today/l/36994b6d164c4043d2ec43cc7d39f5447d3fc0b10bcc175e4593cd4f929976ea\", \"content\": \"The Weather Channel 및 Weather.com이 제공하는 오늘과 오늘 밤 서울특별시 일기예보, 날씨 상태 및 도플러 레이더.\"}, {\"url\": \"https://weather.naver.com/\", \"content\": \"NAVER 날씨 예) 19시는 19시 정시 기준 습도 1mm 이하 5mm 이하 10mm 이하 20mm 이하 50mm 이하 60mm 이하 25mm 이하 10mm 이하 5mm 이하 1mm 이하 천리안위성 2A호(GEO-KOMPSAT-2A)의 관측 자료를 최대 120분 범위로 제공합니다. 이를 통해 태풍 중심위치, 집중호우 탐지, 산불, 황사 등 다양한 관측 정보를 제공합니다. 전국에 설치된 기상레이더의 관측 정보를 최대 120분 범위로 제공합니다. 관측 강수량 정보기상청이 제공하는 관측 강수량 자료를 제공합니다. 최근 1시간 강수량 : 매 10분 기준, 과거 1시간 동안 내린 비의 양을 의미합니다. 1시간 누적 강수량 : 매 정시 기준, 과거 1시간 동안 내린 비의 양을 의미합니다. 일 누적 강수량 : 하루 동안(00시~24시) 내린 비의 양을 의미합니다. 읍・면・동 강수량 기준 : 전국에 분포한 기상청 측정소의 관측 자료를, 인접한 읍・면・동에 반영해 제공합니다.\"}]', name='tavily_search_results_json', id='5463a12f-32dd-4baa-9fbe-f664883bc157', tool_call_id='call_ddBYt55HfLgXwfnMH3PPbm4s', artifact={'query': '서울 날씨', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': '서울특별시 일기예보 및 날씨 | Weather.com', 'url': 'https://weather.com/ko-KR/weather/today/l/36994b6d164c4043d2ec43cc7d39f5447d3fc0b10bcc175e4593cd4f929976ea', 'content': 'The Weather Channel 및 Weather.com이 제공하는 오늘과 오늘 밤 서울특별시 일기예보, 날씨 상태 및 도플러 레이더.', 'score': 0.4338141, 'raw_content': None}, {'title': '네이버 날씨 홈', 'url': 'https://weather.naver.com/', 'content': 'NAVER 날씨 예) 19시는 19시 정시 기준 습도 1mm 이하 5mm 이하 10mm 이하 20mm 이하 50mm 이하 60mm 이하 25mm 이하 10mm 이하 5mm 이하 1mm 이하 천리안위성 2A호(GEO-KOMPSAT-2A)의 관측 자료를 최대 120분 범위로 제공합니다. 이를 통해 태풍 중심위치, 집중호우 탐지, 산불, 황사 등 다양한 관측 정보를 제공합니다. 전국에 설치된 기상레이더의 관측 정보를 최대 120분 범위로 제공합니다. 관측 강수량 정보기상청이 제공하는 관측 강수량 자료를 제공합니다. 최근 1시간 강수량 : 매 10분 기준, 과거 1시간 동안 내린 비의 양을 의미합니다. 1시간 누적 강수량 : 매 정시 기준, 과거 1시간 동안 내린 비의 양을 의미합니다. 일 누적 강수량 : 하루 동안(00시~24시) 내린 비의 양을 의미합니다. 읍・면・동 강수량 기준 : 전국에 분포한 기상청 측정소의 관측 자료를, 인접한 읍・면・동에 반영해 제공합니다.', 'score': 0.27588186, 'raw_content': None}], 'response_time': 3.82})]}}\n",
      "-----------------------------------------------------------------------\n",
      "{'agent': {'messages': [AIMessage(content='서울의 날씨에 대한 정보를 확인하려면 아래 링크를 방문해 보세요:\\n\\n1. [The Weather Channel - 서울 날씨](https://weather.com/ko-KR/weather/today/l/36994b6d164c4043d2ec43cc7d39f5447d3fc0b10bcc175e4593cd4f929976ea)\\n2. [NAVER 날씨](https://weather.naver.com/)\\n\\n이 링크들에서 오늘의 날씨와 예보를 자세히 확인할 수 있어요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 605, 'total_tokens': 723, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='run-51b686e9-95d3-45d9-bd1b-38ff4f6bf6d8-0', usage_metadata={'input_tokens': 605, 'output_tokens': 118, 'total_tokens': 723, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"내가 사는 곳의 날씨를 알려줘.\")]},\n",
    "    config\n",
    "):\n",
    "    print(chunk)  # 에이전트의 응답 출력\n",
    "    print(\"-----------------------------------------------------------------------\")  # 응답 구분선 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce1f71f-ef0b-4dd7-b4c5-566f4cb0187a",
   "metadata": {},
   "source": [
    "Example [LangSmith trace](https://smith.langchain.com/o/351c6cd9-1396-5c74-9478-1ee6a22a6433/projects/p/acec9d4d-4978-4597-adff-789cd42e200f?timeModel=%7B%22duration%22%3A%227d%22%7D&peek=17495aca-857d-4d57-95e7-6c05ac8348d7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae908088",
   "metadata": {
    "id": "ae908088"
   },
   "source": [
    "새로운 대화를 시작하려면 사용 중인 `thread_id`를 변경하기만 하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e5680a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='죄송하지만, 당신의 이름을 알 수 있는 방법이 없습니다. 이름을 알려주시면 그에 대한 질문이나 대화를 이어갈 수 있습니다!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 85, 'total_tokens': 119, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='run-edd2dce7-9a71-41d0-9534-3880d05ec8a1-0', usage_metadata={'input_tokens': 85, 'output_tokens': 34, 'total_tokens': 119, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"xyz123\"}}\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"내 이름이 뭐야?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a588e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
