{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5630b0ca",
   "metadata": {
    "id": "5630b0ca"
   },
   "source": [
    "# **Retrieval Augmented Generation (RAG) 애플리케이션 구축: Part 1**\n",
    "\n",
    "LLM(대규모 언어 모델)에 의해 가능해진 가장 강력한 애플리케이션 중 하나는 **정교한 질문-답변(Q&A) 챗봇**입니다. 이러한 애플리케이션은 특정 출처 정보를 기반으로 질문에 답할 수 있습니다. 이 기술은 **Retrieval Augmented Generation (RAG)**이라고 불립니다.\n",
    "  \n",
    "이 노트북에서는 **텍스트 데이터 소스**를 기반으로 간단한 Q&A 애플리케이션을 구축하는 방법을 다룰 것입니다. 진행하면서 전형적인 Q&A 아키텍처를 설명하고, 고급 Q&A 기술을 위한 추가 자료를 강조할 것입니다. 또한 **LangSmith**가 애플리케이션을 추적하고 이해하는 데 어떻게 도움을 줄 수 있는지 살펴볼 것입니다. 애플리케이션이 복잡해질수록 LangSmith의 도움은 더욱 중요해질 것입니다.  \n",
    "\n",
    "이 노트북은 **비정형 데이터(unstructured data)**에 대한 Q&A에 초점을 맞추고 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 전형적인 **RAG 애플리케이션**\n",
    "\n",
    "두 가지 주요 구성 요소로 이루어져 있습니다:  \n",
    "\n",
    "1. **인덱싱(Indexing)**: 데이터 소스를 수집하고 인덱싱하는 파이프라인입니다. *일반적으로 오프라인에서 수행됩니다.*  \n",
    "2. **검색 및 생성(Retrieval and Generation)**: 실행 시간에 사용자 쿼리를 받아 인덱스에서 관련 데이터를 검색한 후, 모델에 전달하여 답변을 생성합니다.  \n",
    "\n",
    "---\n",
    "\n",
    "### **인덱싱 단계**  \n",
    "일반적인 데이터 인덱싱 과정은 다음과 같습니다:  \n",
    "\n",
    "1. **로드(Load)**  \n",
    "   - 먼저 데이터를 불러와야 합니다. 이는 문서 로더(Document Loaders)를 사용하여 수행됩니다.  \n",
    "\n",
    "2. **분할(Split)**  \n",
    "   - 텍스트 분할기(Text Splitters)를 사용해 큰 `문서(Document)`를 작은 청크(chunk)로 나눕니다.  \n",
    "   - 이렇게 하면 검색이 더 효율적이며, 모델의 제한된 컨텍스트 윈도우에 맞출 수 있습니다.  \n",
    "\n",
    "3. **저장(Store)**  \n",
    "   - 분할된 데이터를 저장하고 인덱싱할 장소가 필요합니다.  \n",
    "   - 일반적으로 벡터 스토어(VectorStore)와 임베딩 모델(Embeddings)을 사용합니다.  \n",
    "\n",
    "![index_diagram](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/rag_indexing.png?raw=1)\n",
    "\n",
    "---\n",
    "\n",
    "### **검색 및 생성 단계**  \n",
    "일반적인 검색 및 생성 과정은 다음과 같습니다:  \n",
    "\n",
    "4. **검색(Retrieve)**  \n",
    "   - 사용자 입력을 받아 검색기(Retriever)를 사용하여 저장된 데이터에서 관련 청크를 검색합니다.  \n",
    "\n",
    "5. **생성(Generate)**  \n",
    "   - 챗 모델(ChatModel) 또는 LLM이 검색된 데이터를 포함한 프롬프트를 사용해 답변을 생성합니다.  \n",
    "\n",
    "![retrieval_diagram](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/rag_retrieval_generation.png?raw=1)\n",
    "\n",
    "---\n",
    "\n",
    "인덱싱이 완료된 후에는 LangGraph를 오케스트레이션 프레임워크로 사용하여 **검색 및 생성 단계**를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7ab59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU \\\n",
    "# python-dotenv \\\n",
    "# langchain \\\n",
    "# langchain-community \\\n",
    "# openai \\\n",
    "# anthropic \\\n",
    "# langchain-openai \\\n",
    "# langchain-anthropic \\\n",
    "# langchain-google-genai \\\n",
    "# python-dotenv\n",
    "\n",
    "# !pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph langchainhub tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f3a87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ab6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain 추적(Tracing) 설정 활성화\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba74a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 사용할 언어 모델의 이름을 지정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 사용할 임베딩 모델의 이름을 지정\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d92cbc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InMemoryVectorStore - 메모리 내에서 벡터 데이터를 저장 및 빠른 검색\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2d316-922c-4318-b72d-486fd6813b94",
   "metadata": {
    "id": "93b2d316-922c-4318-b72d-486fd6813b94"
   },
   "source": [
    "이  노트북에서는 **웹사이트 콘텐츠에 대한 질문에 답변하는 애플리케이션**을 구축합니다.  \n",
    "사용할 웹사이트는 **[LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/)**라는 **Lilian Weng**의 블로그 포스트입니다.  \n",
    "이 애플리케이션을 통해 블로그 게시물의 내용을 바탕으로 질문에 답할 수 있습니다.  \n",
    "\n",
    "우리는 약 **50줄의 코드**로 간단한 **인덱싱 파이프라인**과 **RAG 체인**을 만들 수 있습니다.   \n",
    "**텍스트를 로드, 분할, 인덱싱**한 후, **사용자 질문을 기반으로 관련 데이터를 검색**하고 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9ea6a-f914-4f50-8e35-52e6c34b8001",
   "metadata": {
    "id": "efa9ea6a-f914-4f50-8e35-52e6c34b8001"
   },
   "source": [
    "## **단계별 상세 설명**\n",
    "\n",
    "## **1. 인덱싱 {#indexing}**\n",
    "\n",
    "### **문서 불러오기 (Loading documents)**\n",
    "\n",
    "먼저 블로그 게시물의 내용을 불러와야 합니다. 이를 위해 **Document Loaders**를 사용할 수 있습니다.  이 객체는 데이터 소스에서 정보를 불러와 **Document** 객체 목록으로 반환합니다.  \n",
    "\n",
    "이 경우, **[WebBaseLoader](https://python.langchain.com/docs/integrations/document_loaders/web_base/)**를 사용합니다.  \n",
    "- `WebBaseLoader`는 `urllib`를 사용해 **웹 URL에서 HTML을 로드**합니다.  \n",
    "- 이후, `BeautifulSoup`을 사용해 **텍스트로 파싱**합니다.  \n",
    "\n",
    "#### **HTML → 텍스트 변환 커스터마이징**  \n",
    "- `bs_kwargs` 매개변수를 사용하여 `BeautifulSoup` 파서에 사용자 정의 옵션을 전달할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe124b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43130\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# HTML에서 `post-content`, `post-title`, `post-header` 클래스를 가진 콘텐츠만 추출하여 텍스트 변환\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "\n",
    "# WebBaseLoader를 사용해 웹 페이지의 내용을 불러옵니다.\n",
    "# Define the headers with a User-Agent\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer}\n",
    ")\n",
    "\n",
    "# 문서 로드하여 Document 객체 목록 반환\n",
    "docs = loader.load()\n",
    "\n",
    "# 로드된 문서가 정확히 하나인지 검증합니다.\n",
    "assert len(docs) == 1\n",
    "\n",
    "# 문서의 총 문자 수 출력\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8643579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43130\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "# 문서 길이\n",
    "print(len(docs[0].page_content))\n",
    "# 첫번째 500 자 출력\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f11795-e19f-4697-bc6e-6d477355a1cd",
   "metadata": {
    "id": "e6f11795-e19f-4697-bc6e-6d477355a1cd"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **문서 분할 (Splitting documents)**  \n",
    "\n",
    "불러온 문서는 **42,000자 이상**으로, 많은 언어 모델의 **컨텍스트 윈도우(context window)**에 넣기에는 너무 길므로, 너무 긴 입력은 **정보를 효과적으로 찾아내기 어려울 수 있습니다.**  \n",
    "\n",
    "이 문제를 해결하기 위해, **`Document`를 작은 청크(chunk)로 분할**하여 **임베딩(embedding)** 및 **벡터 저장(vector storage)**에 사용합니다.  \n",
    "이렇게 하면 블로그 게시물의 **가장 관련성 높은 부분만 검색**할 수 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "**RecursiveCharacterTextSplitter**는 문서를 **공통 구분자(예: 줄바꿈)**를 사용해 재귀적으로 분할합니다.  일반적인 텍스트 사용 사례에 가장 적합한 텍스트 분할기입니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6606d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "블로그 글을 66개의 하위 문서로 분할했습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,            # 각 청크의 최대 문자 수 (1,000자)\n",
    "    chunk_overlap=200,          # 청크 간 겹치는 문자 수 (200자)\n",
    "    add_start_index=True,       # 원본 문서에서 각 청크의 시작 인덱스를 추적\n",
    ")\n",
    "\n",
    "# 불러온 문서를 설정한 기준에 따라 청크로 분할\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 분할된 청크(서브 문서)의 개수 출력\n",
    "print(f\"블로그 글을 {len(all_splits)}개의 하위 문서로 분할했습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5193e01-6cf1-45b9-9ba5-38caf75162a6",
   "metadata": {
    "id": "f5193e01-6cf1-45b9-9ba5-38caf75162a6"
   },
   "source": [
    "### **문서 저장 (Storing documents)**\n",
    "\n",
    "이제 분할된 **66개의 텍스트 청크**를 인덱싱해야 합니다. 이를 통해 검색할 수 있습니다.  \n",
    "\n",
    "1. 각 **문서 청크**의 내용을 **임베딩(embedding)** 합니다.\n",
    "2. 이 **임베딩을 벡터 스토어(Vector Store)**에 삽입합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b8da4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7918a249-3578-462b-a9dd-60855a891a27', 'd0c98964-554b-4e13-b1d1-53bbdb382d4c', '407fa5b1-5927-4dab-b9bf-a0de5b0e6d28']\n"
     ]
    }
   ],
   "source": [
    "# 분할된 문서 청크(all_splits)는 임베딩되어 벡터 스토어에 저장됩니다.\n",
    "# 반환값은 저장된 각 문서 청크의 고유 ID 목록입니다.\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# 첫 세 개의 문서 ID를 출력합니다.\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57666234-a5b3-4abc-b079-755241bb2b98",
   "metadata": {
    "id": "57666234-a5b3-4abc-b079-755241bb2b98"
   },
   "source": [
    "이로써 **인덱싱(Indexing)** 단계가 완료되었습니다!\n",
    "\n",
    "- 이제 우리는 **질의 가능한 벡터 스토어**를 보유하고 있습니다.  \n",
    "- 블로그 게시물의 청크가 저장되어 있으며, 사용자 질문을 받으면 **관련 청크를 반환**할 수 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "## **2. 검색 및 생성 (Retrieval and Generation)**\n",
    "\n",
    "이제 실제 **애플리케이션 로직(application logic)**을 작성해 보겠습니다.  \n",
    "간단한 애플리케이션을 만들어 다음과 같은 작업을 수행할 것입니다:  \n",
    "\n",
    "1. **사용자 질문을 입력받기**  \n",
    "2. **질문과 관련된 문서 청크 검색**  \n",
    "3. **검색된 문서와 질문을 모델에 전달**  \n",
    "4. **모델이 답변을 생성**  \n",
    "\n",
    "---\n",
    "\n",
    "- 생성 단계에서는 **챗 모델(Chat Model)**을 사용할 것입니다.  \n",
    "- RAG용 프롬프트는 LangChain의 **프롬프트 허브(prompt hub)**에 저장되어 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "### **프로세스 요약**  \n",
    "1. **사용자 질문 입력 → 문서 검색 → 답변 생성**  \n",
    "2. 관련 문서를 검색하고 질문과 함께 모델에 전달  \n",
    "3. 모델이 **최종 답변**을 생성  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ee032d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (사용자의 질문이 여기 들어갑니다.) \n",
      "Context: (검색된 문서 내용이 여기 들어갑니다.) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# RAG에 최적화된 프롬프트를 LangChain Hub에서 가져옵니다.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 프롬프트를 사용해 예제 메시지를 생성합니다.\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(검색된 문서 내용이 여기 들어갑니다.)\",\n",
    "     \"question\": \"(사용자의 질문이 여기 들어갑니다.)\"}\n",
    ").to_messages()\n",
    "\n",
    "# 프롬프트로부터 생성된 메시지가 하나인지 확인\n",
    "assert len(example_messages) == 1\n",
    "\n",
    "# 첫 번째 메시지의 내용을 출력\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dfe84d-cc19-4227-bee4-56b69508ab11",
   "metadata": {
    "id": "77dfe84d-cc19-4227-bee4-56b69508ab11"
   },
   "source": [
    "**LangGraph**를 사용하여 **검색(Retrieval)** 과 **생성(Generation)** 단계를 하나의 애플리케이션으로 통합할 것입니다. 이를 통해 다음과 같은 이점을 얻을 수 있습니다:\n",
    "\n",
    "- **다양한 호출 모드 지원:**  \n",
    "  한 번 정의된 애플리케이션 로직은 **스트리밍(streaming)**, **비동기(async)**, **배치 호출(batched calls)** 등 여러 호출 모드를 자동으로 지원합니다.\n",
    "\n",
    "- **간편한 배포:**  \n",
    "  [**LangGraph 플랫폼**](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/)을 통해 애플리케이션을 더 쉽게 배포할 수 있습니다.\n",
    "\n",
    "- **자동 추적:**  \n",
    "  **LangSmith**가 애플리케이션의 모든 단계를 자동으로 추적합니다.\n",
    "\n",
    "- **확장성:**  \n",
    "  [**데이터 지속성(persistence)**](https://langchain-ai.github.io/langgraph/concepts/persistence/) 및 [**사람의 승인(Human-in-the-loop approval)**](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)과 같은 핵심 기능을 최소한의 코드 변경으로 손쉽게 추가할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## **LangGraph를 사용하기 위한 3가지 핵심 요소**\n",
    "\n",
    "1. **애플리케이션의 상태(State)**  \n",
    "2. **애플리케이션의 노드(Nodes)** - 각 단계의 로직  \n",
    "3. **애플리케이션의 흐름(Control Flow)** - 예) 단계의 순서 및 실행 흐름\n",
    "\n",
    "---\n",
    "\n",
    "### **1. 상태(State)**\n",
    "\n",
    "애플리케이션의 [**상태(state)**](https://langchain-ai.github.io/langgraph/concepts/low_level/#state)는 다음을 관리합니다:  \n",
    "- 애플리케이션에 입력되는 데이터  \n",
    "- 각 단계 간에 전달되는 데이터  \n",
    "- 애플리케이션에서 최종적으로 출력되는 데이터  \n",
    "\n",
    "**상태(State)** 는 일반적으로 `TypedDict`로 정의하지만, 더 정교한 검증과 유연성이 필요하다면 [Pydantic BaseModel](https://langchain-ai.github.io/langgraph/how-tos/state-model/)을 사용할 수 있습니다.\n",
    "- TypedDict: 간단하게 상태의 구조(예: 어떤 데이터가 어떤 형태로 들어와야 하는지)를 정의할 때 사용  \n",
    "- Pydantic BaseModel: 더 복잡한 데이터 검증, 기본값 설정, 사용자 정의 검증 등을 할 때 사용\n",
    "\n",
    "---\n",
    "\n",
    "### **간단한 RAG 애플리케이션 상태 예시**\n",
    "\n",
    "간단한 **RAG 애플리케이션**에서는 다음 항목만 추적하면 됩니다:  \n",
    "1. **입력 질문(question)**  \n",
    "2. **검색된 문맥(retrieved context)**  \n",
    "3. **생성된 답변(generated answer)**  \n",
    "\n",
    "다음 단계에서는 **노드(Nodes)** 를 정의하여 각 애플리케이션 단계를 설정하는 방법을 살펴보겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7bab225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# List: 여러 Document 객체를 리스트로 저장할 때 사용\n",
    "# TypedDict: 상태(State) 객체 정의를 위한 구조체 역할\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# 애플리케이션의 상태(State) 객체 정의\n",
    "class State(TypedDict):\n",
    "    question: str          # 사용자 질문을 저장하는 문자열 필드`\n",
    "    context: List[Document]    # 검색된 문서 목록을 저장하는 필드\n",
    "    answer: str           # 생성된 답변을 저장하는 문자열 필드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77868d9a-892f-4b2c-b706-850f96b4464f",
   "metadata": {
    "id": "77868d9a-892f-4b2c-b706-850f96b4464f"
   },
   "source": [
    "#### **노드 (애플리케이션 단계)**\n",
    "\n",
    "간단한 두 단계로 구성된 시퀀스를 정의해 보겠습니다:  \n",
    "\n",
    "1. **검색 (Retrieval)**  \n",
    "2. **생성 (Generation)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "121cb602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자의 질문을 기반으로 벡터 스토어에서 관련 문서를 검색\n",
    "def retrieve(state: State):\n",
    "    # 벡터 스토어에서 질문과 유사도가 높은 문서를 검색\n",
    "    retrieved_docs = vector_store.similarity_search(state['question'])\n",
    "    return {\"context\": retrieved_docs}\n",
    "    \n",
    "# 검색된 문서와 질문을 기반으로 모델이 답변을 생성\n",
    "def generate(state: State):\n",
    "    # 검색된 문서(context) 내용을 하나의 문자열로 합칩니다.\n",
    "    combined_context = \"\\n\\n\".join(doc.page_content for doc in state['context'])\n",
    "    \n",
    "    # 프롬프트에 질문과 문서 내용을 전달하여 모델 입력 메시지 생성\n",
    "    messages = prompt.invoke({\"context\": combined_context, \"question\": state[\"question\"]})\n",
    "    \n",
    "    # LLM(대규모 언어 모델)에 메시지를 전달하여 답변 생성\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac9dc3-d73d-48c3-be05-4b60e0b8bc17",
   "metadata": {
    "id": "d1ac9dc3-d73d-48c3-be05-4b60e0b8bc17"
   },
   "source": [
    "애플리케이션을 하나의 **`graph` 객체**로 컴파일합니다.  여기서는 **검색 단계**와 **생성 단계**를 **단일 시퀀스(sequence)**로 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "768c7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "# StateGraph 초기화\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 검색(retrieve)과 생성(generate) 단계를 순차적으로 실행하도록 설정 (node 자동 추가)\n",
    "workflow.add_sequence([retrieve, generate])\n",
    "\n",
    "# 그래프의 시작점(START)을 'retrieve' 단계와 연결\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "\n",
    "# 그래프를 컴파일하여 최종 그래프 객체를 생성\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b127f4-8411-4214-8cdd-a281771ab708",
   "metadata": {
    "id": "20b127f4-8411-4214-8cdd-a281771ab708"
   },
   "source": [
    "**LangGraph**는 애플리케이션의 **흐름 제어(Control Flow)** 를 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a344e208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# 그래프의 흐름을 Mermaid 형식으로 시각화한 이미지를 표시합니다.\n",
    "# - get_graph(): 그래프 객체를 가져옵니다.\n",
    "# - draw_mermaid_png(): Mermaid 다이어그램을 PNG 이미지로 렌더링합니다.\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tjC2SdXftfcz",
   "metadata": {
    "id": "tjC2SdXftfcz"
   },
   "source": [
    "**LangGraph**는 RAG 애플리케이션을 구축하는 데 반드시 필요하지는 않습니다. 실제로 개별 구성 요소를 사용하여 동일한 애플리케이션 로직을 구현할 수도 있습니다. \n",
    "그럼에도 LangGraph를 사용하는 이유는 복잡한 워크플로우 관리, 상태 관리 및 공유, 에이전트 간 협업 강화, 유연성과 확장성 때문 입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f80d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Decomposition은 복잡한 작업을 여러 단계로 나누어 더 작은 작업으로 변환하는 과정입니다. 이 방법은 모델이 각 단계에서 여러 사고를 생성하도록 하여 문제 해결을 용이하게 합니다. 따라서, Task Decomposition은 복잡한 문제를 관리 가능한 여러 작업으로 나누는 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "question = \"Task Decomposition이 뭔가요? 한국어로 답해주세요.\"\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(question)\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "message = prompt.invoke({\"question\": question, \"context\": docs_content}).to_messages()\n",
    "answer = llm.invoke(message)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7dc4d-cac8-4be9-b44c-df097dc28c81",
   "metadata": {
    "id": "31f7dc4d-cac8-4be9-b44c-df097dc28c81"
   },
   "source": [
    "\n",
    "\n",
    "**LangGraph의 주요 장점은 다음과 같습니다:**  \n",
    "\n",
    "- **다양한 호출 모드 지원:**  \n",
    "  - 출력 토큰을 스트리밍하거나 각 단계의 결과를 스트리밍하려면 위의 로직을 다시 작성해야 합니다.  \n",
    "  - LangGraph는 이러한 호출 모드를 기본적으로 지원합니다.  \n",
    "<p></p>\n",
    "- **자동 추적 및 배포 지원:**  \n",
    "  - **LangSmith**를 통해 애플리케이션 단계를 자동으로 추적합니다.  \n",
    "  - [**LangGraph 플랫폼**](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/)을 통해 손쉽게 배포할 수 있습니다.  \n",
    "<p></p>\n",
    "- **지속성, 인간 개입(Human-in-the-loop) 지원:**  \n",
    "  - LangGraph는 지속성(persistence) 및 인간 개입(human-in-the-loop) 기능을 기본적으로 지원합니다.  \n",
    "\n",
    "---\n",
    "\n",
    "많은 사용 사례에서는 RAG가 **대화형 경험(conversational experience)** 속에서 사용됩니다.  \n",
    "즉, 사용자는 **상태(State)를 유지하면서 문맥이 반영된 답변**을 받을 수 있어야 합니다.    \n",
    " LangGraph의 **상태 관리(state management)** 및 **지속성(persistence)** 은 이러한 애플리케이션을 훨씬 더 쉽게 구현할 수 있도록 돕습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9c057-5a08-46a3-8c7d-6a314d1e777d",
   "metadata": {
    "id": "eee9c057-5a08-46a3-8c7d-6a314d1e777d"
   },
   "source": [
    "**LangGraph**는 다양한 호출 모드(**동기(sync)**, **비동기(async)**, **스트리밍(streaming)**)를 지원합니다.  \n",
    "\n",
    "---\n",
    "\n",
    "### **호출 (Invoke)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3215793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='646c63d0-668c-4dc0-9194-a17bc767bf81', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='407fa5b1-5927-4dab-b9bf-a0de5b0e6d28', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='a277b3a8-c4fb-4974-b6e1-e22f706ed011', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17413}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), Document(id='e10d4830-0a1a-4f88-8eaa-2a5c65ed2930', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 32069}, page_content='},\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.')]\n",
      "\n",
      "\n",
      "Answer: Task Decomposition은 복잡한 문제를 여러 단계로 나누어 각 단계에서 여러 생각을 생성하는 과정을 말합니다. 이를 통해 큰 작업을 더 작고 관리하기 쉬운 작업으로 변환하여 문제 해결을 용이하게 합니다. 이 과정은 LLM(대규모 언어 모델)을 사용하여 수행될 수 있으며, 여러 가지 방법으로 문제를 세분화할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 그래프를 호출하여 사용자 질문에 대한 답변을 생성\n",
    "result = app.invoke({\"question\": \"Task Decomposition이 뭔가요? 한국어로 답해주세요.\"})\n",
    "\n",
    "# 검색된 문서(Context) 내용을 출력합니다.\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "\n",
    "# 생성된 답변(Answer)을 출력합니다.\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef88f30-40ca-476b-808d-794cb72d401f",
   "metadata": {
    "id": "4ef88f30-40ca-476b-808d-794cb72d401f"
   },
   "source": [
    "**스트림 단계(Stream Steps):**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f51436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='646c63d0-668c-4dc0-9194-a17bc767bf81', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='407fa5b1-5927-4dab-b9bf-a0de5b0e6d28', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='a277b3a8-c4fb-4974-b6e1-e22f706ed011', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17413}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), Document(id='e10d4830-0a1a-4f88-8eaa-2a5c65ed2930', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 32069}, page_content='},\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'Task Decomposition은 복잡한 작업을 더 작고 간단한 단계로 나누는 과정입니다. 이를 통해 모델은 \"단계별로 생각하라\"는 지시를 받아 문제를 해결할 수 있습니다. 즉, 큰 작업을 여러 개의 관리 가능한 작업으로 변환하여 모델의 사고 과정을 명확히 하는 것입니다.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 그래프의 각 단계를 스트리밍 모드로 실행\n",
    "# - stream_mode=\"updates\": 각 단계가 완료될 때마다 업데이트를 반환\n",
    "for step in app.stream(\n",
    "    {\"question\": \"Task Decomposition이 뭔가요? 한국어로 답해주세요.\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")    # 각 단계의 결과 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860142d-d50b-4526-a03f-a59a763117fe",
   "metadata": {
    "id": "f860142d-d50b-4526-a03f-a59a763117fe"
   },
   "source": [
    "**토큰(Tokens) 스트리밍:**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c0d404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Task| De|composition|은| 복|잡|한| 작업|을| 더| 작|고| 관리|하기| 쉬|운| 단계|로| 나|누|는| 과정|입니다|.| 이는| 주|로| L|LM|(|대|형| 언|어| 모델|)을| 사용|하여| 단계|별|로| 생각|하고| 계획|하도록| 유|도|하여| 수행|됩니다|.| 이| 과정|은| 작업|의| 이해|와| 효|율|적인| 수행|을| 도|와|줍|니다|.||"
     ]
    }
   ],
   "source": [
    "# 그래프를 스트리밍 모드로 실행하여 토큰 단위로 출력을 받습니다.\n",
    "# - stream_mode=\"messages\": 토큰이나 메시지 단위로 스트림을 제공합니다.\n",
    "for message, metadata in app.stream(\n",
    "    {\"question\": \"Task Decomposition이 뭔가요? 한국어로 답해주세요.\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    # 각 메시지의 내용을 출력합니다.\n",
    "    # 'end=\"|\"'는 토큰 사이에 '|' 기호를 추가하여 구분합니다.\n",
    "    print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406534d4-66a3-4c27-b277-2bd2f5930cf5",
   "metadata": {
    "id": "406534d4-66a3-4c27-b277-2bd2f5930cf5"
   },
   "source": [
    "#### **출처 반환 (Returning sources)**  \n",
    "\n",
    "그래프 상태(`State`)에 **검색된 문맥(context)** 을 저장함으로써, 모델이 생성한 답변의 출처를 `\"context\"` 필드에서 확인할 수 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "**챗 모델(Chat Models)** 은 **메시지의 시퀀스(sequence)** 를 입력으로 받아들이고 **하나의 메시지**를 반환합니다.  \n",
    "\n",
    "- **문서**: 챗 모델 사용법에 대한 자세한 설명  \n",
    "- **통합 옵션**: 25개 이상의 통합 옵션 제공  \n",
    "\n",
    "---\n",
    "\n",
    "### **프롬프트 커스터마이징 (Customizing the prompt)**  \n",
    "\n",
    "위에서 보여준 것처럼, 프롬프트는 **프롬프트 허브(Prompt Hub)** 에서 불러올 수도 있고  **쉽게 커스터마이징** 할 수도 있습니다. 예를 들어:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e4cdaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"다음 문맥을 사용하여 마지막에 있는 질문에 답하세요.\n",
    "답을 모를 경우, 모른다고 말하세요. 답을 지어내려고 하지 마세요.\n",
    "최대 세 문장으로 답변을 작성하고, 가능한 한 간결하게 유지하세요.\n",
    "항상 답변의 끝에는 \"질문해 주셔서 감사합니다!\"라고 말하세요.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217cf819-da76-4595-8f75-33f931f1f92a",
   "metadata": {
    "id": "217cf819-da76-4595-8f75-33f931f1f92a"
   },
   "source": [
    "## **쿼리 분석 (Query analysis)**  \n",
    "\n",
    "- Query - 정보 검색을 위해 사용되는 질의어\n",
    "\n",
    "지금까지 우리는 **사용자 입력 쿼리(raw input query)** 를 그대로 사용해 검색을 수행했습니다. 하지만 **모델을 사용해 검색용 쿼리를 생성**하는 것은 몇 가지 장점이 있습니다:  \n",
    "\n",
    "- **구조화된 필터(Structured Filters)** 추가:  \n",
    "   예를 들어, *\"2020년 이후의 문서를 찾아라.\"* 와 같은 필터링을 적용할 수 있습니다.\n",
    "\n",
    "    사용자 입력 쿼리: \"2020년 이후의 문서를 찾아라.\"\n",
    "\n",
    "    모델이 생성한 구조화된 검색용 필터:\n",
    "\n",
    "  ```\n",
    "    {\n",
    "      \"query\": \"\",\n",
    "      \"filters\": {\n",
    "        \"date\": {\n",
    "          \"gte\": \"2020-01-01\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "  ```\n",
    "   \n",
    "- **사용자 쿼리 최적화:**  \n",
    "   모델은 다면적이거나 불필요한 언어가 포함된 사용자 쿼리를 **더 효과적인 검색 쿼리로 재작성**할 수 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "**쿼리 분석(Query Analysis)** 은 **모델을 사용해 사용자 입력을 최적화된 검색 쿼리로 변환하거나 구성**하는 기술입니다.  \n",
    "이 단계를 애플리케이션에 쉽게 통합할 수 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "### **예시: 메타데이터 추가**  \n",
    "\n",
    "설명을 위해 벡터 스토어에 있는 문서에 **메타데이터(metadata)** 를 추가해 보겠습니다.  \n",
    "이렇게 하면 나중에 **필터링(filtering)** 을 통해 특정 섹션이나 조건에 맞는 문서를 더 효과적으로 검색할 수 있습니다.  \n",
    "\n",
    "    예시: 복잡한 표현 간소화\n",
    "    사용자 입력 쿼리: \"저렴한 가격에 구매할 수 있는 최신 스마트폰 추천해줘.\"\n",
    "    최적화된 검색 쿼리: \"최신 스마트폰 저렴한 가격\"\n",
    "\n",
    "다음 단계에서는 메타데이터를 추가하고, 이를 기반으로 **쿼리 분석**을 수행하는 방법을 살펴보겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56e2b8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'start_index': 8,\n",
       " 'section': '시작 부분'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 문서 청크 수를 계산합니다.\n",
    "total_doc_length = len(all_splits)\n",
    "print(total_doc_length)\n",
    "\n",
    "# 문서를 세 개의 섹션(시작, 중간, 끝)으로 나누기 위한 기준을 설정\n",
    "section_size = total_doc_length // 3\n",
    "print(section_size)\n",
    "\n",
    "# 각 문서 청크에 메타데이터(section)를 추가합니다.\n",
    "for i, doc in enumerate(all_splits):\n",
    "    if i < section_size:\n",
    "        # 첫 번째 섹션: 시작 부분\n",
    "        doc.metadata[\"section\"] = \"시작 부분\"\n",
    "    elif i < 2*section_size:\n",
    "        # 두 번째 섹션: 중간 부분\n",
    "        doc.metadata[\"section\"] = \"중간 부분\"\n",
    "    else:\n",
    "        # 세 번째 섹션: 끝 부분\n",
    "        doc.metadata[\"section\"] = \"끝 부분\"\n",
    "        \n",
    "# 첫 번째 문서 청크의 메타데이터를 출력합니다.\n",
    "all_splits[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114878bd-a334-41ed-8013-ec4ce0a9112b",
   "metadata": {
    "id": "114878bd-a334-41ed-8013-ec4ce0a9112b"
   },
   "source": [
    "### 벡터 스토어(Vector Store) 업데이트\n",
    "\n",
    " **메타데이터 필터링(metadata filtering)** 과 같은 특정 기능을 활용하기 위해 벡터 스토어에 있는 문서를 업데이트해야 합니다.  \n",
    "\n",
    "여기서는 간단한 [**InMemoryVectorStore**](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html)를 사용합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a814230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 내에서 벡터 데이터를 저장 및 검색할 수 있는 벡터 스토어\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# InMemoryVectorStore 초기화\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "# 메타데이터와 함께 분할된 문서(all_splits)를 벡터 스토어에 추가합니다.\n",
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08aaccd-b3df-45e9-8646-d6ea20215e62",
   "metadata": {
    "id": "c08aaccd-b3df-45e9-8646-d6ea20215e62"
   },
   "source": [
    "다음으로 **검색 쿼리(Search Query)** 를 위한 **스키마(schema)** 를 정의해 보겠습니다.  \n",
    "\n",
    "이를 위해 **구조화된 출력(Structured Output)** 을 사용할 것입니다.  \n",
    "\n",
    "여기서는 검색 쿼리가 **문자열 쿼리(string query)** 와 **문서 섹션(document section)** 으로 구성된다고 정의합니다.  \n",
    "- **문서 섹션(document section)**: `\"시작 section\"`, `\"중간 section\"`, `\"마지막 section\"` 중 하나  \n",
    "\n",
    "하지만 이 구조는 필요에 따라 자유롭게 정의할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d723394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# 검색 쿼리 스키마 정의\n",
    "class Search(TypedDict):\n",
    "    # query: 검색 실행을 위한 문자열 쿼리\n",
    "    query: Annotated[str, ..., \"실행할 query 검색문\"]\n",
    "    # section: 검색할 문서 섹션 \n",
    "    section: Annotated[Literal[\"시작 부분\", \"중간 부분\", \"끝 부분\"], ..., \"query할 부\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399a870-cb06-4219-9b4f-cfa37cb8ab0f",
   "metadata": {
    "id": "6399a870-cb06-4219-9b4f-cfa37cb8ab0f"
   },
   "source": [
    "마지막으로, 사용자의 **원본 입력(raw input)** 을 기반으로 **검색 쿼리(query)** 를 생성하는 단계를 **LangGraph 애플리케이션**에 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0848c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 정의했던 State 클래스에 'query' 필드를 추가하여 확장합니다.\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    \n",
    "# 원본 질문을 기반으로 구조화된 쿼리를 분석합니다.\n",
    "def analyze_query(state: State):\n",
    "    # LLM을 구조화된 출력(Search)으로 설정합니다.\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    \n",
    "    # 사용자 질문을 구조화된 쿼리(Search)로 변환합니다.\n",
    "    structured_query = structured_llm.invoke(state[\"question\"])\n",
    "    \n",
    "    # 구조화된 쿼리를 반환합니다.\n",
    "    return {\"query\": structured_query}\n",
    "    \n",
    "# 검색 단계: 구조화된 쿼리와 필터를 사용하여 문서를 검색합니다.\n",
    "def retrieve(state: State):\n",
    "    structured_query = state[\"query\"]  # 구조화된 검색 쿼리를 가져옵니다.\n",
    "    \n",
    "    # 유사도 검색을 수행하며 'section' filter를 적용합니다.\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        structured_query['query'],    # 질의어\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") ==  structured_query[\"section\"]  # section filter\n",
    "    )\n",
    "    \n",
    "    # 검색된 문서 목록을 반환합니다.\n",
    "    return {\"context\": retrieved_docs}\n",
    "    \n",
    "# 생성 단계: 검색된 문서와 질문을 기반으로 답변을 생성합니다.\n",
    "def generate(state: State):\n",
    "    # 검색된 문서(context) 내용을 하나의 문자열로 합칩니다.\n",
    "    combined_context = \"\\n\\n\".join(doc.page_content for doc in state['context'])\n",
    "    \n",
    "    # 프롬프트에 질문과 문서 내용을 전달하여 모델 입력 메시지 생성\n",
    "    messages = prompt.invoke({\"context\": combined_context, \"question\": state[\"question\"]})\n",
    "    \n",
    "    # LLM(대규모 언어 모델)에 메시지를 전달하여 답변 생성\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "    \n",
    "# 그래프 빌더를 사용해 애플리케이션 흐름을 정의합니다.\n",
    "# - 단계 순서: analyze_query → retrieve → generate\n",
    "workflow = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "    \n",
    "# 그래프 시작점(START)을 analyze_query 단계와 연결합니다.\n",
    "workflow.add_edge(START, \"analyze_query\")\n",
    "\n",
    "# 그래프를 컴파일하여 최종 그래프 객체를 생성합니다.\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1bf027c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# 그래프의 구조를 Mermaid 다이어그램으로 출력합니다.\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653cf8dc-a201-43ea-9965-02fcfd2fc316",
   "metadata": {
    "id": "653cf8dc-a201-43ea-9965-02fcfd2fc316"
   },
   "source": [
    "**구현 테스트하기**\n",
    "\n",
    "이제 게시물의 **시작 부분**, **중간 부분**, **끝 부분**에서 문맥을 가져오도록 명확하게 요청하여 우리의 구현을 테스트해 볼 수 있습니다.  \n",
    "\n",
    "모델의 답변에 **다른 정보가 포함될 것**임을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d5e5490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': '시작 부분'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='58468f93-e48d-4c77-bfe0-c94b5a70b424', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192, 'section': '시작 부분'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='341419bb-d65d-41d1-bb5c-6ac3b3eb5b90', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585, 'section': '시작 부분'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='feb86009-cc62-4bad-a4e1-5fd41aa8db94', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2837, 'section': '시작 부분'}, page_content='Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.'), Document(id='41a56d44-1fe3-4ce5-a9d3-6b09e57787d6', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 14987, 'section': '시작 부분'}, page_content='Fig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': '게시물의 시작 부분에서는 Task Decomposition이 복잡한 작업을 여러 단계로 나누어 더 작고 간단한 작업으로 변환하는 과정이라고 언급합니다. 이는 Chain of Thought (CoT) 기법을 통해 모델이 \"단계별로 생각하라\"는 지시를 받으며 수행됩니다. 이러한 접근법은 모델의 사고 과정을 해석하는 데도 도움을 줍니다.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in app.stream(\n",
    "    {\"question\": \"게시물의 시작 부분에서는 **Task Decomposition**에 대해 뭐라고 언급하나요?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3d240c2-4339-42ea-b47d-bf062eec4ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': '중간 부분'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='af00d466-3cb5-4fda-b732-1d3bd021d647', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17413, 'section': '중간 부분'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), Document(id='e779f602-48ef-45e9-a85f-94ac208e8fab', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 29629, 'section': '중간 부분'}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'), Document(id='bf66c1ac-181d-40ac-93cc-0434ed2f81f4', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17803, 'section': '중간 부분'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.'), Document(id='12db90b5-f749-4c36-b63f-9686b3f2e68e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 18660, 'section': '중간 부분'}, page_content='(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': '게시물의 중간 부분에서는 **Task Decomposition**에 대해 LLM이 사용자 요청을 여러 작업으로 나누고, 각 작업에 대해 작업 유형, ID, 의존성 및 인수와 같은 네 가지 속성이 있다고 언급합니다. LLM은 몇 가지 예제를 사용하여 작업 분석 및 계획을 안내합니다. 이를 통해 효과적인 작업 분할과 관리를 수행할 수 있습니다.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in app.stream(\n",
    "    {\"question\": \"게시물의 중간 부분에서는 **Task Decomposition**에 대해 뭐라고 언급하나요?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e859e6ab-ee8f-41fa-9532-56d67ee89074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': '끝 부분'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='33c6fff4-9c9b-4cca-a7fd-85634d77e75e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 32069, 'section': '끝 부분'}, page_content='},\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.'), Document(id='68f836f6-29b4-48d2-b903-2de7c5ccc1be', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39220, 'section': '끝 부분'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='ff10def5-3608-4d78-afec-5419765673af', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 33887, 'section': '끝 부분'}, page_content='FILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.'), Document(id='9ac89a5c-2c3d-4090-8137-06bfbcd362d6', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 33070, 'section': '끝 부분'}, page_content='You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': '게시물의 끝 부분에서는 **Task Decomposition**에 대해 언급하지 않습니다. 주로 긴 계획과 과제 분해의 어려움에 대해 설명하고 있습니다. LLM이 예상치 못한 오류에 직면했을 때 계획을 조정하는 데 어려움을 겪는다는 점을 강조합니다.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in app.stream(\n",
    "    {\"question\": \"게시물의 끝 부분에서는 **Task Decomposition**에 대해 뭐라고 언급하나요?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c86f6-790d-4062-b899-e43151958942",
   "metadata": {},
   "source": [
    "**스트리밍 단계(Streamed Steps)** 와 [**LangSmith 추적(LangSmith Trace)**](https://smith.langchain.com/public/bdbaae61-130c-4338-8b59-9315dfee22a0/r)에서 이제 **검색 단계(Retrieval Step)** 에 입력된 **구조화된 쿼리(Structured Query)** 를 확인할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff88b8d-2785-4598-83fb-fcf2a22142a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
