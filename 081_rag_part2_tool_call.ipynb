{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86fc5bb2-017f-434e-8cd6-53ab214a5604",
   "metadata": {
    "id": "86fc5bb2-017f-434e-8cd6-53ab214a5604"
   },
   "source": [
    "# **Retrieval Augmented Generation (RAG) 애플리케이션 구축: Part 2**\n",
    "\n",
    "많은 Q&A 애플리케이션에서는 **사용자와의 대화가 이어질 수 있도록** 설계해야 합니다.  \n",
    "이를 위해서는 애플리케이션이 과거의 **질문과 답변을 기억(메모리)** 하고, 이를 현재의 논리적 흐름에 통합하는 기능이 필요합니다.\n",
    "\n",
    "###  **대화 기록(Chat History) 관리**\n",
    "\n",
    "여기서는 **과거 대화 기록을 현재 답변 논리에 통합하는 방법**을 중점적으로 다룹니다.  \n",
    "\n",
    "### **두 가지 접근 방식**\n",
    "\n",
    "1. **체인(Chains)**   - 최대 한 번의 검색 단계만 실행합니다.  \n",
    "\n",
    "2. **에이전트(Agents)**   - LLM이 필요에 따라 **여러 번의 검색 단계 (다중 단계 검색)** 를 수행하도록 자유롭게 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "651b53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU \\\n",
    "# python-dotenv \\\n",
    "# langchain \\\n",
    "# langchain-community \\\n",
    "# openai \\\n",
    "# anthropic \\\n",
    "# langchain-openai \\\n",
    "# langchain-anthropic \\\n",
    "# langchain-google-genai \\\n",
    "# python-dotenv\n",
    "# !pip install --upgrade --quiet langgraph langchain-community beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b058beb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a7c2b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain 추적(Tracing) 설정 활성화\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ef4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 사용할 언어 모델의 이름을 지정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 사용할 임베딩 모델의 이름을 지정\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05eee8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_core.vectorstores.in_memory.InMemoryVectorStore at 0x2093a65d370>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ba684-26cf-4860-904e-a4d51380c134",
   "metadata": {
    "id": "fa6ba684-26cf-4860-904e-a4d51380c134"
   },
   "source": [
    "Lilian Weng의 블로그 게시물 \"[LLM 기반 자율 에이전트](https://lilianweng.github.io/posts/2023-06-23-agent/)\"의 내용을 인덱싱한 벡터 스토어를 활용하여 사용자의 질문에 대한 관련 정보를 효과적으로 검색하고 제공할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef3908a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "블로그 글을 66개의 하위 문서로 분할했습니다.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# HTML에서 `post-content`, `post-title`, `post-header` 클래스를 가진 콘텐츠만 추출하여 텍스트 변환\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "\n",
    "# WebBaseLoader를 사용해 웹 페이지의 내용을 불러옵니다.\n",
    "# Define the headers with a User-Agent\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "\n",
    "# 문서 로드하여 Document 객체 목록 반환\n",
    "docs = loader.load()\n",
    "\n",
    "# 로드된 문서가 정확히 하나인지 검증합니다.\n",
    "assert len(docs) == 1\n",
    "\n",
    "# 웹 페이지에서 데이터를 로드\n",
    "# 텍스트를 작은 청크로 분할\n",
    "# - chunk_size: 각 청크의 최대 문자 수 (1000자)\n",
    "# - chunk_overlap: 청크 간 겹치는 문자 수 (200자)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# 로드된 문서를 청크로 나누고 리스트로 반환\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 분할된 청크(서브 문서)의 개수 출력\n",
    "print(f\"블로그 글을 {len(all_splits)}개의 하위 문서로 분할했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e575234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 청크를 벡터 스토어에 인덱싱\n",
    "# - vector_store: 텍스트 임베딩 벡터를 저장하고 검색하는 데 사용되는 데이터 저장소입니다.\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac23bf1-8f8e-4594-bfb2-6044991d9140",
   "metadata": {},
   "source": [
    "### 기존 방식: 상태(state) 기반 접근법 \n",
    "- **RAG 애플리케이션**에서는 사용자 입력, 검색된 문서, 그리고 생성된 답변을 각각 상태(state)라는 구조 안에 별도의 키(key)로 저장했습니다.  \n",
    "- 예를 들면:  \n",
    "   ```python\n",
    "   state = {\n",
    "       \"question\": \"고양이는 몇 살까지 살아요?\",\n",
    "       \"context\": [\"고양이의 평균 수명은 12-18년입니다.\"],\n",
    "       \"answer\": \"고양이는 보통 12-18년 정도 삽니다.\"\n",
    "   }\n",
    "   ```\n",
    "- 하지만 이런 방식은 **대화의 흐름을 자연스럽게 표현하기 어려울 수 있습니다.**  \n",
    "\n",
    "---\n",
    "\n",
    "### 새로운 방식: 메시지(messages) 기반 접근법\n",
    "- 사람들은 대화를 할 때 메시지 시퀀스(sequence of messages)를 주고받습니다.  \n",
    "- **메시지 방식**은 사용자와 어시스턴트 간의 대화를 보다 **자연스럽고 직관적으로 표현**합니다.  \n",
    "- 여기에는 다음과 같은 요소들이 포함됩니다:  \n",
    "   1. **사용자 메시지(User Message):** 사용자의 질문이나 요청  \n",
    "   2. **어시스턴트 메시지(Assistant Message):** AI가 생성한 답변  \n",
    "   3. **도구 메시지(Tool Message):** 검색된 문서나 기타 참고 자료  \n",
    "\n",
    "---\n",
    "\n",
    "### 왜 메시지 방식이 더 나은가? \n",
    "- **더 직관적:** 실제 대화처럼 시간 순서대로 메시지를 쌓아올립니다.  \n",
    "- **유연함:** 검색된 문서나 외부 도구의 결과도 **메시지 형태**로 자연스럽게 추가할 수 있습니다.  \n",
    "- **일관성 유지:** AI가 맥락을 유지하면서 이전 대화와의 연관성을 이해하기 쉽습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **새로운 메시지(messages) 방식:**\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"고양이는 몇 살까지 살아요?\"},\n",
    "    {\"role\": \"tool\", \"content\": \"검색 결과: 고양이의 평균 수명은 12-18년입니다.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"고양이는 보통 12-18년 정도 삽니다.\"}\n",
    "]\n",
    "```\n",
    "---\n",
    "\n",
    "**즉, 메시지 방식은 RAG 애플리케이션을 더 자연스럽고 직관적으로 만들기 위한 개선된 표현 방식입니다.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335abbbf-109f-4eca-9563-d2f6c77995d5",
   "metadata": {},
   "source": [
    "**도구 호출(tool-calling)** 을 활용해 검색 단계와 상호작용하는 것에는 또 다른 이점이 있습니다. 바로 **검색에 사용할 쿼리를 모델이 직접 생성할 수 있다는 점**입니다.  \n",
    "\n",
    "이것은 특히 **대화형 환경(conversational setting)** 에서 중요합니다. 사용자의 질문이 **대화 이력(chat history)** 을 기반으로 문맥화되어야 할 수 있기 때문입니다.  \n",
    "\n",
    "---\n",
    "\n",
    "### **예시 대화**  \n",
    "\n",
    "> **Human:** \"Task Decomposition이란 무엇인가요?\"  \n",
    "> **AI:** \"Task Decomposition은 복잡한 작업을 더 작고 단순한 단계로 나누어, 에이전트나 모델이 더 쉽게 관리할 수 있도록 만드는 과정입니다.\"  \n",
    "> **Human:** \"일반적으로 Task Decomposition을 수행하는 방법에는 어떤 것들이 있나요?\"  \n",
    "\n",
    "- 이 시나리오에서 모델은 `\"Task Decomposition의 일반적인 접근법\"`과 같은 검색 쿼리를 생성할 수 있습니다.  \n",
    "- **도구 호출(tool-calling)** 은 이런 과정을 자연스럽게 지원합니다.  \n",
    "\n",
    "---\n",
    "\n",
    "### **도구 호출의 장점**  \n",
    "\n",
    "1. **쿼리 최적화(Query Optimization)**  \n",
    "   - 모델은 사용자 입력을 더 효과적인 검색 쿼리로 **재작성(rewrite)** 할 수 있습니다.   \n",
    "<p></p>\n",
    "2. **대화 이력(Contextualization)**  \n",
    "   - 모델은 대화 기록을 활용해 사용자 질문을 더 명확한 검색어로 변환할 수 있습니다.  \n",
    "<p></p>\n",
    "3. **직접 응답 지원**  \n",
    "   - 검색 단계가 필요 없는 질문(예: \"Hello!\"와 같은 인사말)에 대해 바로 응답할 수 있습니다.  \n",
    "\n",
    "이제 검색 단계를 **도구(tool)** 로 전환해 보겠습니다. 이렇게 하면 모델이 검색을 더 자연스럽고 효율적으로 수행할 수 있습니다.  \n",
    "\n",
    "- response_format=\"content_and_artifact : 이 설정은 도구의 출력이 두 부분으로 구성됨을 나타냅니다:  \n",
    "    콘텐츠(content): 모델이 처리할 수 있는 문자열 형태의 요약 또는 설명입니다.  \n",
    "    아티팩트(artifact): 모델 외부에서 사용될 실제 데이터나 객체입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9ce2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# 검색(retrieve) 함수를 도구로 정의\n",
    "# - response_format=\"content_and_artifact\": 결과를 콘텐츠(content)와 아티팩트(artifact)로 반환\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"\n",
    "    주어진 쿼리와 관련된 정보를 검색합니다.\n",
    "    - query: 검색할 텍스트 쿼리입니다.\n",
    "    \"\"\"    \n",
    "    # 벡터 스토어에서 유사도 검색 수행. 가장 유사한 두 개의 문서를 반환.\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    \n",
    "    # 검색된 문서를 문자열로 직렬화\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    \n",
    "    # 직렬화된 결과(content)와 원본 문서 목록(artifact) 반환.\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d848d-f5b5-4bc7-a15d-1ed1f1105c04",
   "metadata": {},
   "source": [
    "```\n",
    "# serialized 예시\n",
    "class Doc:\n",
    "    def __init__(self, metadata, page_content):\n",
    "        self.metadata = metadata\n",
    "        self.page_content = page_content\n",
    "\n",
    "retrieved_docs = [\n",
    "    Doc(metadata=\"Document 1\", page_content=\"This is the first document.\"),\n",
    "    Doc(metadata=\"Document 2\", page_content=\"This is the second document.\")\n",
    "]\n",
    "\n",
    "serialized = \"\\n\\n\".join(\n",
    "    f\"Source: {doc.metadata}\\nContent: {doc.page_content}\"\n",
    "    for doc in retrieved_docs\n",
    ")\n",
    "\n",
    "print(serialized)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2300c04-019c-4c65-a104-3dbf17c924b7",
   "metadata": {
    "id": "c2300c04-019c-4c65-a104-3dbf17c924b7"
   },
   "source": [
    "### **대화 기록(chat history)의 상태(Stateful) 관리**\n",
    "\n",
    "1. 애플리케이션을 컴파일할 때 **[체크포인터(checkpointer)](https://langchain-ai.github.io/langgraph/concepts/persistence/)** 를 설정합니다.  그래프의 각 노드가 상태(state)에 메시지를 추가하기 때문에,    **호출(invocation)** 이 반복되어도 일관된 **대화 기록(chat history)** 이 유지됩니다.\n",
    "\n",
    "2. LangGraph에는 간단한 **인메모리 체크포인터(In-memory Checkpointer)** 가 내장되어 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4de34b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad23c71-3c99-4d9d-b494-9b7a08a557c0",
   "metadata": {
    "id": "0ad23c71-3c99-4d9d-b494-9b7a08a557c0"
   },
   "source": [
    "## **에이전트(Agents)**\n",
    "\n",
    "**에이전트(Agents)** 는 **대규모 언어 모델(LLMs)의 추론 능력(reasoning capabilities)** 을 활용하여 실행 중에 의사 결정을 내릴 수 있도록 합니다.  \n",
    "\n",
    "에이전트를 사용하면 **검색(retrieval) 프로세스의 일부 권한을 모델에 위임**할 수 있습니다.  \n",
    "\n",
    "- **체인(chain)** 방식보다 예측 가능성은 떨어질 수 있지만,  \n",
    "- **여러 번의 검색 단계**를 실행하거나,  \n",
    "- **단일 검색을 반복적으로 수행**할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### **간단한 RAG ReAct 에이전트 구성**\n",
    "  \n",
    "**LangGraph**의 [**사전 구축된 ReAct 에이전트 생성자(pre-built ReAct agent constructor)**](https://langchain-ai.github.io/langgraph/how-tos/#langgraph.prebuilt.chat_agent_executor.create_react_agent)를 사용하면, 한 줄의 코드로 이를 구현할 수 있습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7b77651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent  # 사전 구축된 ReAct 에이전트 생성자\n",
    "\n",
    "# ReAct 에이전트 생성\n",
    "# - [retrieve]: 에이전트가 사용할 도구 목록입니다.\n",
    "# - checkpointer=memory: 상태(대화 기록 등)를 메모리에 저장.\n",
    "agent_executor = create_react_agent(\n",
    "    llm, \n",
    "    [retrieve], \n",
    "    checkpointer=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4c96eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANYAAAD5CAIAAADUe1yaAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXdcU1fDx8/NXgRI2ES2LKWiAg5wr8f5AFqtaNVWW7WOp3W0tbWt2uqjdmmntlr33uKDggqiWHFVqgytbBnBQCAhITv3/SO+lGJA1NycG3K+H/+IGef8Al/OvffcMzAcxwECAQ8K7AAIewcpiIAMUhABGaQgAjJIQQRkkIIIyNBgB3gR5FKdvE7XJDcoG/V6rW10K9HoGJWGcRyoHD5N6MlgcaiwE5EFzDZ+gQAAACSV6qI/lSV5Si6fZtDjHD6V60BjsCnAFr4BjYkp6vVNjYYmuV4pM3Adqf7duV0jeTxnOuxokLENBWV1ut9P11LpmLMbw78b18WbCTvRy1JZpCrJVUrFGidXRv/xQhrdfs+IbEDB62frHtxq7D/BJagHD3YWy/Pn5Ybfk+sGJLh07+8IOwscyK7g0c0V3WP5oVF82EGI5UaqtFGqGzbVHXYQCJBXQRzHf1lRPGGul6c/G3YWa5B/XV6apxzzpifsINaGvAr+/H7hjJV+XL5NXrO/GPdvynN/l0/6jwh2EKtCUgWPbqqIjRd6+tlF+9eSe1dldVWawa+6wQ5iPch4IZadUhcxgG+H/gEAImIdOQ7Ughty2EGsB+kUrH+sLcxRhPTu5Ncf7dBrmPOlIxLYKawH6RT8Pbmu/3gh7BQwodEpvYc7Xz9bBzuIlSCXguJSNZNNCYjohP1/z0XMKIG4VK3TGmEHsQbkUrDorkLgwbBadbm5uRqNBtbH24fFpZbkKgkqnFSQS8GSPKV/N6516kpOTp41a5ZKpYLy8Wfi352LFLQ29Y+1fAHN2d1KreALN2Cmbizi2j8TARFcWZ2O0CpIAokUlNXqMAwjouSysrJ58+bFxcWNGTNm3bp1RqMxOTl5/fr1AIDhw4dHRUUlJycDAHJychYuXBgXFxcXFzd37tyCggLTxxsaGqKiovbs2bNy5cq4uLi33nrL7MctC41OUTTolTK9xUsmGyS699AkN3D4hIyi+/zzz0tLS5cuXapUKm/dukWhUGJjY6dPn753795NmzbxeDwfHx8AQFVVlUajmTNnDoVCOXLkyOLFi5OTk1kslqmQ7du3v/rqq1u2bKFSqe7u7k9/3OJw+TSlXM91JNHviAhI9PWUcj1Bt+OqqqpCQ0MTEhIAANOnTwcACAQCkUgEAOjevbuTk5PpbaNHjx4zZozpcXh4+Lx583Jycvr27Wt6JiIiYsGCBc1lPv1xi8N1pCplBtCFoOLJAokUBACnMQk5EI8ZM2bnzp0bN26cM2eOQCBo620YhmVkZOzdu7ekpITD4QAA6ur+7pyLiYkhIls7MFlU3EjG26eWhUTngmwurVFKyKnPggULlixZkpaWNmHChMOHD7f1tm3bti1fvjw8PPybb7559913AQBG4989c2y2tW8YNtRqOXYwSoNECnL41Ca5gYiSMQxLSko6derUoEGDNm7cmJOT0/xS8ygNjUazY8eO+Pj4pUuXRkZGRkREdKRkQgd5EHdyTCpIpKCDgE4n5kBs6kDhcrnz5s0DANy/f7+5VZNIntyNValUGo0mLCzM9N+GhoZWrWArWn2cCBwENAenzt8KkugbunozKwtVigY9z9I/9w8++IDH4/Xt2zcrKwsAYPKsR48eVCr1q6++mjBhgkajmThxYlBQ0MGDB4VCoUKh+OWXXygUSmFhYVtlPv1xy2YuzVfSGRSMQsjfJKmgrlq1CnaGv2mQ6HRqo5sPy7LFVlRUZGVlnTt3TqVSLVq0aPDgwQAAPp/v7u5+/vz5K1euyOXycePG9erV6+rVq4cPHy4rK1u0aJGvr++xY8emTZum0+l2794dFxcXHh7eXObTH7ds5jsZDd5BbLcuFv5RkBByDVktv68szlUOnmRHAzbbIvmXqiGTXXlOnX+KJ4kOxAAAn1Du9bNScZnaw9f8X39DQ0N8fLzZl0QiUUVFxdPPDxo0aPXq1ZZO2po5c+aYPWqHhYU132VpSe/evb/++uu2Ssv9XcZzotmDf6RrBQEAlYWq6+fqEheanz9hMBhqamrMvoRh5r8Lm812dna2dMzWSCQSnc7MLd22UjGZTKGwzWGRv6wonvmpL5Pd+S+HyaggACDj8OOuPXmirhzYQeBw76pMqzb2Hkb4nw1JIFGnTDNDJrud2yVWKQjpIyQ55Q+aiu8q7Mc/kioIAJj6vs/+DeWwU1ibxnrd+b01/57vDTuIVSHjgdiERmXYt7582oc+dnJKVFOmTttbM22FD8UO+gJbQl4FTa3CgY2PJsz19OjsEzof3Jb/eVk2+b3OPirGHKRW0MTFAzUqpSF2vIvVBlRbk4qHTVeT60RB7NgJLrCzwMEGFAQAlOQqrybXBkRw3X1Y/t25neBQpVYaSvKU1SVqWa0udrzQ4jeEbAjbUNDEwzuND+8oSnKVYX34NAbG5dO4jlQmi2oTX4BKxZRyfZNcr5Dp5VJ9TZnavxs3uLeDT4id9j01Y0sKNlNaoJQ91inleqXMoNcbjRbtvdHpdPn5+T169LBkoQCweVTciHP4NJ4jTejJ8Ars5Ge3HccmFSSUurq6qVOnpqWlwQ5iL5C0XxBhPyAFEZBBCrYGw7Dg4GDYKewIpGBrcBz/66+/YKewI5CCrcEwzNHRThe/hwJSsDU4jstkMtgp7AikoBk8PDxgR7AjkIJmEIvFsCPYEUjB1mAY1nKmHIJokIKtwXE8Pz8fdgo7AimIgAxSsDUYhrWz+hbC4iAFW4PjuFQqhZ3CjkAKmsHFxU4HMEMBKWiG2tpa2BHsCKQgAjJIwdZgGBYYGAg7hR2BFGwNjuNFRUWwU9gRSEEEZJCCZmhe7hdhBZCCZjC7IiCCIJCCCMggBVuDRspYGaRga9BIGSuDFERABinYGjSJ08ogBVuDJnFaGaQgAjJIwdagecRWBinYGjSP2MogBVuDRspYGaRga9BIGSuDFERABiloBnd3d9gR7AikoBna2mkRQQRIQTOg8YLWBCloBjRe0JogBVuDBmtZGaRga9BgLSuDFDSDSGR+T3gEEaCtb54we/ZssVhMpVKNRmN9fb1AIMAwTK/Xp6SkwI7WyUGt4BMmT57c2NhYVVUlFos1Gk11dXVVVRWG2fx+i+QHKfiEUaNGBQQEtHwGx/HevXvDS2QvIAX/ZurUqRzO3/tienh4JCUlQU1kFyAF/2bUqFG+vr6mx6YmMDQ0FHaozg9S8B/MmDGDy+WamsCpU6fCjmMXIAX/wYgRI3x9fXEc79mzJ7pNZx1osAO8CEYD3iDRyep0RHQoxY+cC5pO/mvgzOJcpcULp1KBsxuDL6RbvGTbxfb6Be/flOdek6sVBg9/dpPcohuyEw/PmVZ+X+nsSo8eKUAbs5uwMQULrssL/1QOfNWDQrHhHjuN2pC2q3L4VDe3LizYWeBjS+eCD+80/pWjHDzF06b9AwAwWdTxc33O7aqpf6yFnQU+NqMgjuN3s2Sx/3aDHcRi9JvgdjOtHnYK+NiMgiqFof6xjsmmwg5iMRyF9EcPmmCngI/NKCiX6jvZmRObR2NzqXqtEXYQyNiMghgAqkY97BQWRlanQyMhbEZBRGcFKYiADFIQARmkIAIySEEEZJCCCMggBRGQQQoiIIMUREAGKYiADFIQARmkoAUQi6urxVWwU9gqSMGXpbKqImn6hAcP0EpILwhSEOA4XllV8cIfN+j1tjX5gWzY5Ay6DnLvXs6evdvu5eYAAEJDus2b925I8JN5mfkFuT/+9HVx8UOhwMXPP7Cw8MHunccZDIZard62/ceL6ee0Wk0Xke/kya8PHTISAHD02P70jLRXJ03bvv3HOmlt166hy5as9PHxqxZXzXxjEgBg9ZoPVwMwatS4D99fBft72xiduRUUi6s0Ws3r0+fMnPG2WFz14YrFarUaAFBTI162fD6NRvt4xRc9e0ZfvZo5YfwkBoNhNBo/XvnetWuXpyW98d67HwUFhXz+xUcpZ0+ZSisoyD18eM/SpSvXrP5K8rjmvxs+AwAIBS4ff/QFAOCNWfO+27RtetKbsL+07dGZW8Hhw0ePGDHG9DgkJHzJ0nn3cnOio/qev5CiUqk++2S9QCCMjR30590/sq9nJU2ddflK+t17dw7sS3ZxcQUADB/2L5Wq6djxA2NG/9tUyNovvhUIhACAxMTXfvr5W5lc5sh3DO4aCgDw8fGLiIiE+nVtlc6sIIZhV7IyDh/ZW1ZWYlqvqF5aBwCQSGq4XK5JJgzDvLxENTXVAIDs7Cy9Xp80fUJzCQaDgcvlNf+XxXoy89fd3RMAUFcrceSj3epels6s4O4923bs3DIxcerbcxbVSWtXr/nQiBsBAN7eXZRKZXFxYUBAkE6nKyx8EBkZBQCor68TCl2++WpLy0KoNDM/IjqNDgAwGG1sIj056bQK6nS6/Qd2jB0Tv3DBUgDA48d/byUyauS4I0f3fbTy3ZEjxub8eVuv18+a8TYAwMGB39BQ7+7uyWQyoWa3Lzrt5YhWq9VoNMH/fwkskzcAAIxGIwDA0dFp4YJlTCarpKQoqnffX7fuF4l8AAC9esUYDIbTyUebC1GpVM+siMlkmQ7KRH6bzkynbQW5XG5AQNDxEwcFAqFSodi1+xcKhVJcXAgAKLift/HL1YsXvk+j0ykUSnV1pUAgpFKpI4aPST5zfMvWzdXiquCuoYWFf2Vdzdj521EWq73Jo25u7l6e3oeP7mWx2XK5bMrk1ymUTvuHTQSdVkEAwCcfr9uwcdWaz1eIRD7z579XVPTXsWMH5r692MPd09PTe8OXq5u7lLsGhXy3eTuLxfpyw4+/bvs+PT31zJnjIpHPhPGTaObOBVuCYdjKles2frn6hx+/cnPzSIif0r6yiFbYzLJGNWXqS0clY+Z0sUhpBoOBSqWaHlzJyli95sOvv/q5V89oixTecfZ+UfT2ugAq3a6nEnfmVrAtystL//PeW/36DggKDNZoNZcvX2SxWCJvH9i57BR7VJDL5Q0b+q/s7CvnL6TweA4R3SPffXeFmxvaABYO9qigUOiycMFSU2cNAjro2g0BGaQgAjJIQQRkkIIIyCAFEZBBCiIggxREQAYpiIAMUhABGaQgAjI2oyCVBhwEnW33QFcRk0K162EytqSg0ItZfFcBO4UlkdZotGojZjO/AaKwmR8AhmHBvR3EpZ1nuyJJubprJK8Db+zk2IyCAIBhr7ldPlajVnaGeWul+Y3F9+TRowSwg8DHZkZNm9CoDHvWlkUOEfKc6M5uDJvKDgAAOADSanWjVFdWoJj8nujmzZsxMTGwQ0HGxhQ0cXb/g9L7jR7unrJancULx3FcrVaz2YTsV+3izQQA+ISwXxngBAAoKChYtmzZ8ePH7XraKG6DLFq0iLjCN23aFBcXd/r0aeKqaEl1dfWjR4/q6uqsUx0JsaVzQQBAeno6AOC7774jqPzq6uorV66oVKrDhw8TVEUrPDw8RCIRhmFTpkxRKDrVJX8HsSUFp0yZ4u3tTWgVR44cKS0tBQCUl5efOXOG0Lpa4uzsvHbt2tTUVKvVSB5sQ0GxWKxSqdauXRsSEkJcLZWVlZmZmabHSqXy0KFDxNX1NEFBQRMnTgQALFq0SKPRWLNquNiAgkeOHMnOzmaz2UFBQYRWdOLEibKysub/lpWVnTp1itAazTJ79uzffvvN+vXCwgYULCsri4+PJ7qWqqqqjIyMls8olcp9+/YRXe/TREZGzp8/HwDwww8/WL9260NqBX///XcAwLJly6xQ18GDB01NoGnpI9P9mEePHlmh6raIjo4eMGAAxABWAvYluXm0Wm3//v3r6+utX7VEIhk5cqT16zWLUqnEcfzevXuwgxAIGVvBhoaGsrKyixcvOjk5Wb92g8EQGhpq/XrNYlocFsfxt956C3YWoiCdgqdPny4tLQ0KCoK1PpVOpzP1y5CHiIiI+fPnV1RUdMqOQ3IpKJFI7ty5ExkJc91wlUrl7k669WV69eolEokqKyuhXCERCokULC0txTDss88+gxujrq6OTifp2NiQkJCampo//vgDdhBLQhYFP/30Uzab7eLiAjsIqK+v9/Eh70JvS5YscXd3VyqVsINYDFIoWFFR0adPH5Ic/kpKSsjwl9AO3t7ebDY7KipKLpfDzmIB4CuoUql4PN7YsWNhB3mCRqMJDAyEneIZUCiUmzdvXrhwobkX03aBrODy5cuvXbsGpfOlLdLT04ODg2GneDYYhiUmJhqNRlsf3ABzicvbt28vXry4SxfLLB9tERoaGvh8vpeXF+wgHYVGo2VmZgYGBhJ9A504oLWCUqm0a9eupPIPAJCdne3n5wc7xfOxbt26hoYG2CleHDgKHj16dOvWrXw+H0rt7XD58uWBAwfCTvHcREVFZWRk2GhnDQQFxWKxk5PTihUrrF/1M5HJZLaoIABgyJAhly5dSklJgR3kubHJ6UsEkZqampmZuW7dOthB7Atrt4ILFy7Mzc21cqUd5MSJEwkJCbBTvCz79++XSGxpQzyrKpiZmTl+/Pju3btbs9IOUlJSQqPRoqOtvQGTxUlKSho/frwNHdzQgfgJy5YtGzt27JAhQ2AHsTus1woeOnSItIfg+/fvV1dXdyb/CgoKbOUC2UoKlpaWHj58mJyHYADAt99+a53pAVYjLCxs8+bNpP2bb4mVFMQwbNu2bdap63k5efKkSCTq2bMn7CAWZuvWrTZxB9nezwX1ev2oUaMuXrwIO4j9Yo1WMD09fc2aNVao6AVYsmQJabO9PE1NTcOHD4ed4hlYQ8Hs7Ox+/fpZoaLnZc+ePQEBAbGxsbCDEAWHw5k5c+bZs2dhB2kP+z0QP3z48PvvvyduhSREB7GGglqtlsFgEF3L8xITE3Pt2jUqlQo7COFkZWX5+fmJRCLYQcxD+IE4Ly9vzpw5RNfyvEyfPn3Xrl324J+pCdi8eTPsFG1CuIIKhYJsoyl/+OGHadOmhYWFwQ5iJYYOHerj42MwkHSNbrs7F9y2bZtOpzOtG4QgA4S3gnq9XqvVEl1LBzl9+nRlZaUd+ldQUHDp0iXYKcxDuILp6enQZ6ebuHnzZl5eHknCWBk2m/3999/DTmEewqcvCYVCMtwmunv37k8//bRjxw7YQeDg5+f39ttvk7Nrwi7OBYuKilasWGG1FcwRz4U17o7APResqKhYvnw58u/s2bM3btyAncIM1lAwISFBLBZboaKnefjw4TvvvHP8+HEotZMKqVSalZUFO4UZrDGVffDgwTNnzjQYDHK53M3NzWqbKdy/f//gwYOnT5+2TnUkZ8iQIS0XcycPBCo4cODApqYm0yKhGIaZHoSHhxNXY0uKioo+/vjjY8eOWac68uPl5UXOVSIIPBAPHTqUQqGYxquanmEymX369CGuxmZyc3N//fVX5F9Lamtr169fDzuFGQhUcNWqVeHh4S2vuF1dXXv06EFcjSZycnK+/PJLcv64IYLjODl7p4m9HNmwYUPzEi04jnM4HKLvF1+5cuXMmTO7du0itBZbxMnJiYTjRQhX0N3d/b333jOtGIlhGNFNYGpq6rFjx1auXEloLTYKnU6fNGkS7BRmILxTJi4uLjExkcvl8ng8Qk8ET548mZmZuWnTJuKqsGl0Ot2GDRtgpzBDh66I9TqjSvHiN9mmvvpmWdHjoqKiAJ9ujfX6Fy6nHTIyMvLuFaPlYNrHtJsV2XjGDbqCG/K7V2RSsZbNe6nRnc39MgSh1WrdvHlVRU0Br/CiRzgLvex4k/N/snz58osXLzZ3ipnOiHAcJ89E9/ZawRtp0toq3YBEDwcBSTdBaIXRgDdItCk7xcOT3D394OycQzbmz5+fn59fU1PTsneMVMt4tnkueP2cVCbRD0hwtxX/AAAUKibwYMYv8L144HFNuRp2HFIQEBDQu3fvlsc6DMNItYaieQXrH2trKzV9x7lZPY9lGDrV81ZaPewUZGHGjBktN9QQiUSvvfYa1ET/wLyCtZUaHCfw1I1oHJzpjx42aTXwxymSgaCgoJiYGNNjHMcHDBhAki1eTJhXUCEzuHax7XMp33CutFoDOwVZeP31193c3Ezb5kybNg12nH9gXkGdxqhT23YTIq/TA2DDDbllCQwM7NOnD47jgwYNIlUTCHnfEURbGI14+f0mRb1eKdfrdbhKaYH5lz28pqt7dg0RxF44UPPypbHYVAabwuFT+c50n1DOyxSFFCQXBTfkD24rKh42eQXz9VqcSqdS6DSAWaJTgsKK6TdWZwS6JgsU1qjADTq9Qa+j0zWnt1b5hnODe/JCohxeoCikIFnIvy7POlXr6uNA4zp0H0GuY2X7OPsKGh835d1WX02uGxAv7Nrz+URECsJHpTCk7KjRGSgBfUQ0hu2tMYJhGN+dCwCX58q/lS4tuKkYO9uDSu3oiTj8nTjtnPIHyt1ry3jeAo8QV1v0ryUMNs0z3I3h7LTl/aLHjzp6awApCJOaR+rM49KQgb5Mts3cgnomLB6j23D/lB018roOzZxECkKjJE+RtlfSJZKM8zleHr9o0fGfxOKyZ7eFSEE4KBr0Fw90Wv9M+EV5H/++Uq97RgczUhAO53bX+MV4w05BOIF9vf732zO6IZGCELh1vt4AGDS6bV98dAQml6FUYnnXZO28BykIgeyUOrcgZ9gprIRbgOBqsrSdN1hSwfyCXI3mpUYGXMq8MGRYVHl5qeVCkY7bF6Te4QJCx5C/MGs2jjt6ysKTX2lMqtDHIff3NhtCiyl4LjV5wcJZarXKUgV2VgpuKliOtj0K6Xlh8lj3bynaetViCr5k+2cnyKU6tdLIdrCvqS08IVvySK1rY/imZW7QnUtN3rR5PQAgPnE4AOCD9z/716jxAIC0tP/tO7CjqqpCKHQZOyZhWtIbpiU+9Hr9jp1bUtPOyGQNvr7+s2bOjYsd/HSx2dlZv2z7vqqqwsPDa8L4SYkJUyySFiKPHjQ5i3gEFV5YfDvl/E9V4r8ceIIg/6jRI+bzHVwAACvXDps4/oPcgkv5D66yWby+0QkjhzyZ024wGC5c2p5966RWqwoM6K3TETXbwcXPoaygKSjSzHe3TCvYJyZ28qvTAQD/Xbvpu03b+sTEAgBSU8/8d8NnXbuGfrJy3eBBI37b8fO+/U8WOf3q6y8OHd4zbmzCxx994eHh9cmny+7evdOqzKamplVrPmDQGUuXrOzfb2BdnS3tNN4WtdU6HCfkEvBh0c1fdy92d/OfHP/xwP5JxaV3tuxYoNU+Uerg8dVeHsHvzN7Sq8fotPRf8x9cNT1/4syX5y9tDw3unzBuGYPOUqkbicgGADAYsHqJ+ZsllmkFnZ0FXl4iAEBYWHdHRyfTAPFtv/0YERG58qMvAAADBwxtbJQfPLRrYuLU2trHqWlnZrw+Z9bMuQCAQQOHTZ+RsHPX1m++3tKyzPoGqUajGTBg6Ijhoy0SkgwoZXoak01EySf/93XfqISEcU+2tA0O6vPld1MeFGZHhA8GAMT0mjBs0CwAgJdH8I3bp/4qzA4Pia2oup9968SwQW+MHj4PABDVc2xRCVEzO+lMmqKNKeREjZSpqCivrZVMmfx68zPR0f1Szp6qqCx/8CAfABAX92T/aQzDoqP6nr+Q0qoEL0/vbt1e2btvO4vFHj8ukYSLJL8AKoWB6Wz57kBpfXWNpKRW+ij71smWzzfInnQLMxhPvKdSqY58N5lcAgC4l38JADCw/9Tm92MYUZ10NCalSW5dBRVKBQDAyUnQ/IyDAx8AUCt5rFQqAADOLV7i8x2bmpqUSmXLEjAMW7/uu23bf9iyddORo3tXfLCmR49eBKW1GgQt7N2oqAMAjBgy55Xwf2ws7+Dg8vSbKRSa0WgAADQ0iFksHpfjSEimVuCYsY3vbmHrm+erurm6AwBksobml+rrpSYRXVzcAABy+d8dRVJpHY1GY7Fad1XweLx3//Phrp3HuFzeyk+WmBbMtGm4jlS9xvK7ILFZDgAAnU7j5urX8h+b1d6lD5frrFYrdHprrASu1+gdnM23dxZTkM1iAwBqa59cNAiFLh7unjduXG1+Q2bmBRaLFRQUEhbWHcOw7OtP1j3WarXZ17O6dXuFSqUy6IyWdpo6erw8vRMTXlMoFWJxlaXSwsLBkabXWl5BVxcfJ0ePm38ka7RP+mUNBr1er2v/UyLvUADAnbupFs/zNHqtwcHJvILUVatWPf1sZZHKoAcefs9x4sxic06dPlJaVowBLL/gXkhIuAOPf+jIXomkRqfTHT9x8MLFs9OS3oyO6st34IvF1SdOHgIAq62V/PzztyWlRcuXferp6U2j00+cPHT/QZ6Pj5+L0HXGrMTaWkldXe2Jk4e0Gs3sN9+h0Tp65vDwjtwvjMNr42vDQiHT1Yn1bCcLX5FgGObs5Hnj9un8+1dwgJc9unfizNcGg9a3SwQAIP3KbpFXaEjQk2XNsm+eZLG4PV8Z6ebifzfv4u07KSq1QqGsv3bzRFHJLZFXWHhonGXjAQDUMqV/OEvgbuaE3mIK8h34rq7uly6dv3btSmOjfNSocUFBwc7OgvSMtLPnTjfUS5OS3pg+7U3TjanoqH5KpeLsuVPp6alcDnfZ0pXR0f0AAA48B08Prz/u3KRglLDwiIqK8qyrGVey0oVC1w/fX+Xt/RzbmZJTQQ6fduN/tUJfy59+ubv6ibzDi0tzbueklFfkeXoG9Y4cbeoXbEtBCoUSFhwnqS27m3exuDTHwy1AWl/l7upPhIIlt2uGT3OnUMzcljS/staNVKlWDXoMFjz9kq2Qsr1iUKKLB/kWN9q/8ZGTj5DjaEc3SBprm/TyxoQF5gdHkquRsAfC+/IK81TtKPhX4Y3dh1Y8/Tyb5dBW1/G4UYv6RsVbKmHBg6v7jn769PM4jgOAm+24mffGjyKv0LYK1Cg03WK4bb2KFLQ2kQOdr50pchbxqTTz14J+Pq8seWfP089exkGDAAACdklEQVTjOGhreA2Hbckje6B/b7MBjEYjjuNm9xHnO7i2VZpWpZOLFWHRbS4nhxSEQOx4Yf5tqUeImU47AACDwRIwYA7ot2yA2uL6AfHCdt6AhqxC4JUBTmyWQaN6RqdJJ0DdqHESYu1PbkcKwmH0Gx7F2ZWwUxCL0YgX36ga84ZH+29DCsKBwaTEz/cqudGZLSzOrpj6vs8z34YUhIanPztxoUfJjQrYQSyPQW98eLU86QORs9uzB5cgBWHiKGSMn+ORm1aikneelbGV9eqHWeVTlog4vA5d7CIFIePizVzwTaBRIa/MrdEoYe4d/vKo5JpHf1bTjYp5GwL5HV4lH3XKwAfDsLGzPUtylZdPPOY4sWgcJt+VQ7WdWcZ6jUEuURo0Wp1SMzjRpUvw8614iRQkC/7duf7duUX3FA/vKAuvSgUijk5jpDJoNCaNhCsW4zhu0OgNOj2dQakXq/y7c7vG8vzCX2RZRKQguQiM4AVG8AAA1SUqpcyglOm1GqPaEgv9WhYmh8LiMDh8joMz1d3nGd0u7YMUJCme/oRMMSEh5hVksDAj+Rr/58LRlU7YRAiEJTH/W3JwpkvKbHtdhJK7CqFnZ5jx1Okxr6BbFyYp1zzpKA0SrV83Do2OmkEboM1W0DuIdfmY2Op5LMPFfVV9x7Q3OgNBHtrbjzjvmuxhjqLHIKGzO6OtwW2kQqXQy2p1l4+KJy7ydurArSEEGXjGltglecqczAZxiZpKI/uBWeDJlEm0Ad05MaOFXD660rcZnqFgMxoV2bekw3HA4thAU41oRUcVRCAIAjUbCMggBRGQQQoiIIMUREAGKYiADFIQAZn/A2s7oJwX4YOFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28623a52-7906-440f-8aaf-d6bb5ecbad98",
   "metadata": {
    "id": "28623a52-7906-440f-8aaf-d6bb5ecbad98"
   },
   "source": [
    "**도구 호출(tool invocation)** 이 원래 LLM 호출로 다시 돌아갑니다. \n",
    "\n",
    "- 모델은 검색된 문맥을 사용해 **질문에 답변**할 수도 있고,  \n",
    "- 더 많은 정보를 얻기 위해 **다른 도구 호출(tool call)** 을 생성할 수도 있습니다.  \n",
    "\n",
    "이제 일반적으로 **여러 단계의 반복적 검색(retrieval steps)** 이 필요한 질문을 만들어 테스트해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f5b1eb0-141b-449c-ba5f-dfa3159a7934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "안녕? 내 이름은 길동이야\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요, 길동님! 만나서 반갑습니다. 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
    "\n",
    "# tools 호출이 필요 없는 query\n",
    "input_message = (\n",
    "    \"안녕? 내 이름은 길동이야\" \n",
    ")\n",
    "\n",
    "for event in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb03050f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Task Decomposition의 표준 방법은 무엇인가요??\n",
      "\n",
      "답변을 얻은 후, 해당 방법의 일반적인 확장 방법들을 찾아보세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_fmAl2r5eelGJIMjdMWiBDGoa)\n",
      " Call ID: call_fmAl2r5eelGJIMjdMWiBDGoa\n",
      "  Args:\n",
      "    query: Task Decomposition standard methods\n",
      "  retrieve (call_6AMJRMGPuAYUqXbIkFf4BBKq)\n",
      " Call ID: call_6AMJRMGPuAYUqXbIkFf4BBKq\n",
      "  Args:\n",
      "    query: Task Decomposition common extension methods\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "### Task Decomposition의 표준 방법\n",
      "\n",
      "1. **간단한 프롬프트 사용**: 대형 언어 모델(LLM)을 활용하여 \"Steps for XYZ.\\n1.\" 또는 \"What are the subgoals for achieving XYZ?\"와 같은 프롬프트를 통해 문제를 분해합니다.\n",
      "\n",
      "2. **작업 특화 지침 활용**: 특정 작업에 맞는 지침을 사용하여 예를 들어, \"Write a story outline.\"와 같은 지시를 통해 작업을 정의하고 분해합니다.\n",
      "\n",
      "3. **인간 입력**: 인간의 입력을 통해 작업을 분해하는 방법도 있습니다.\n",
      "\n",
      "### 일반적인 확장 방법\n",
      "\n",
      "Task Decomposition의 확장 방법으로는 다음과 같은 것들이 있습니다:\n",
      "\n",
      "- **Tree of Thoughts**: Yao et al. (2023)에서 제안된 방법으로, 각 단계에서 여러 사고 가능성을 탐색하고 여러 생각을 생성하여 트리 구조를 형성합니다. 이 과정에서 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)를 사용할 수 있으며, 각 상태는 분류기(프롬프트를 통해) 또는 다수결 방식으로 평가됩니다.\n",
      "\n",
      "이러한 방법들은 다양한 상황에 적용될 수 있으며, 문제 해결에 있어 더 깊이 있는 분석과 접근 방식을 제공합니다.\n"
     ]
    }
   ],
   "source": [
    "# tools 호출이 필요한 query\n",
    "input_message = (\n",
    "    \"Task Decomposition의 표준 방법은 무엇인가요??\\n\\n\"\n",
    "    \"답변을 얻은 후, 해당 방법의 일반적인 확장 방법들을 찾아보세요.\"  \n",
    ")\n",
    "\n",
    "for event in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab58d2-92ef-4940-a535-7c8808e75523",
   "metadata": {
    "id": "47ab58d2-92ef-4940-a535-7c8808e75523"
   },
   "source": [
    "### **에이전트의 동작 과정:**\n",
    "\n",
    "1. **표준 Task Decomposition 방법을 검색하기 위한 쿼리**를 생성합니다.  \n",
    "2. 답변을 받은 후, **그 방법의 일반적인 확장 방법**을 검색하기 위한 **두 번째 쿼리**를 생성합니다.  \n",
    "3. 필요한 모든 문맥을 얻은 후, **최종 답변을 생성합니다.**  \n",
    "\n",
    "---\n",
    "\n",
    "**전체 단계, 지연 시간(latency), 기타 메타데이터**를 [**LangSmith 추적(trace)**](https://smith.langchain.com/o/351c6cd9-1396-5c74-9478-1ee6a22a6433/projects/p/acec9d4d-4978-4597-adff-789cd42e200f?timeModel=%7B%22duration%22%3A%227d%22%7D&peek=cdffcf73-c9f6-460c-9c17-43a43180d695)에서 확인할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "이제 LangChain과 LangGraph의 다양한 기능을 활용해 더욱 **강력한 대화형 Q&A 애플리케이션**을 구축할 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c115fd1-8fa7-4bdb-a88d-7f6285c42b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
