from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv()) # read local .env file
#------------------------------------------------------------

import streamlit as st
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def getLLMResponse(form_input, email_sender, email_recipient, email_style):
    llm = ChatOpenAI(temperature=.9, model="gpt-4o-mini")
    
    #PROMPT êµ¬ì¶•ì„ ìœ„í•œ í…œí”Œë¦¿
    template = """
    {style} ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±ëœ ì´ë©”ì¼ì„ ì‘ì„±í•˜ê³ , ì£¼ì œëŠ” ë‹¤ìŒì„ í¬í•¨í•©ë‹ˆë‹¤: {email_topic}.\n\në°œì‹ ì: {sender}\nìˆ˜ì‹ ì: {recipient}
    \n\nì´ë©”ì¼ ë‚´ìš©:
    
    """
    
    #final PROMPT ìƒì„±
    prompt = PromptTemplate(
    input_variables=["style","email_topic","sender","recipient"],
    template=template,)
  
    #LLMì„ ì´ìš©í•œ response ìƒì„±
    response = llm.invoke(prompt.format(email_topic=form_input, sender=email_sender, recipient=email_recipient, style=email_style))

    return response

st.set_page_config(page_title="ì´ë©”ì¼ ìƒì„±ê¸°ê¸°",
                    page_icon='ğŸ“§',
                    layout='centered',
                    initial_sidebar_state='collapsed')
st.header("ì´ë©”ì¼ ìƒì„±ê¸° ğŸ“§")

form_input = st.text_area('ì´ë©”ì¼ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.', height=275)

#ì‚¬ìš©ì ì…ë ¥ì„ ë°›ê¸° ìœ„í•œ UI ì—´ ìƒì„±
col1, col2, col3 = st.columns([10, 10, 5])
with col1:
    email_sender = st.text_input('ë³´ë‚´ëŠ” ì‚¬ëŒëŒ')
with col2:
    email_recipient = st.text_input('ë°›ëŠ” ì‚¬ëŒëŒ')
with col3:
    email_style = st.selectbox('ì‘ì„± ìŠ¤íƒ€ì¼ì¼',
            ('ê³µì‹ ë¬¸ì„œ', 'ê°ì‚¬í•˜ëŠ” ë§ˆìŒ', 'ë¶ˆë§Œì¡± ê°ì •', 'ì¤‘ë¦½ì '),
            index=0)

submit = st.button("ì´ë©”ì¼ ìƒì„±")

if submit:
    response = getLLMResponse(form_input, email_sender, email_recipient, email_style)
    st.write(response.content)
